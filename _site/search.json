[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ ãƒ›ãƒ¼ãƒ ",
    "section": "",
    "text": "ã“ã®ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã¯ã€æ™‚ç³»åˆ—äºˆæ¸¬ã®ãŸã‚ã®çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«è§£æã‚’ä¸­å¿ƒã«ã€æ§˜ã€…ãªPython/Rãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’é›†ç´„ã—ãŸãƒ‡ãƒ¼ã‚¿åˆ†æã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚µã‚¤ãƒˆã§ã™ã€‚\n\n\n\né€æ˜æ€§: å„åˆ†æã«ãŠã‘ã‚‹ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¨ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Œå…¨ã«å…¬é–‹ã—ã¾ã™ã€‚\nå†ç¾æ€§: Quartoã®æ©Ÿèƒ½ã«ã‚ˆã‚Šã€ã™ã¹ã¦ã®ã‚³ãƒ¼ãƒ‰ãŒå†ç¾å¯èƒ½ãªå½¢ã§æ–‡æ›¸åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚\nä¸€å…ƒç®¡ç†: ç•°ãªã‚‹è¨€èªï¼ˆPython, Rï¼‰ã§ä½œæˆã•ã‚ŒãŸãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ã€ä¸€ã¤ã®æ´—ç·´ã•ã‚ŒãŸã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã«ã¾ã¨ã‚ã¦ã„ã¾ã™ã€‚\n\n\n\n\n\nãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒ¼ã®ã€Œ[Analysis]ã€ã¾ãŸã¯ã€Œ[Pythonåˆ†æ]ã€ã‹ã‚‰ã€å„åˆ†æãƒ¬ãƒãƒ¼ãƒˆã®ã‚«ãƒ¼ãƒ‰å½¢å¼ã®ãƒªã‚¹ãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚å„ãƒ¬ãƒãƒ¼ãƒˆã¯ç‹¬ç«‹ã—ãŸãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¨ã—ã¦ä½œæˆã•ã‚Œã¦ãŠã‚Šã€ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã“ã¨ã§ä¸­èº«ã‚’è©³ç´°ã«ç¢ºèªã§ãã¾ã™ã€‚\n\n\n\nSARIMAãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹åŒ»ç™‚è²»ãƒˆãƒ¬ãƒ³ãƒ‰äºˆæ¸¬\nåœ°åŸŸåˆ¥äººå£å‹•æ…‹ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸè¦å› åˆ†æ\nä¿é™ºè¨ºç™‚è²»ã¨è‡ªç”±è¨ºç™‚è²»ã®æ¯”è¼ƒåˆ†æ"
  },
  {
    "objectID": "index.html#ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ç›®çš„",
    "href": "index.html#ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ç›®çš„",
    "title": "ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ ãƒ›ãƒ¼ãƒ ",
    "section": "",
    "text": "é€æ˜æ€§: å„åˆ†æã«ãŠã‘ã‚‹ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¨ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Œå…¨ã«å…¬é–‹ã—ã¾ã™ã€‚\nå†ç¾æ€§: Quartoã®æ©Ÿèƒ½ã«ã‚ˆã‚Šã€ã™ã¹ã¦ã®ã‚³ãƒ¼ãƒ‰ãŒå†ç¾å¯èƒ½ãªå½¢ã§æ–‡æ›¸åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚\nä¸€å…ƒç®¡ç†: ç•°ãªã‚‹è¨€èªï¼ˆPython, Rï¼‰ã§ä½œæˆã•ã‚ŒãŸãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ã€ä¸€ã¤ã®æ´—ç·´ã•ã‚ŒãŸã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã«ã¾ã¨ã‚ã¦ã„ã¾ã™ã€‚"
  },
  {
    "objectID": "index.html#åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’è¦‹ã‚‹",
    "href": "index.html#åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’è¦‹ã‚‹",
    "title": "ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ ãƒ›ãƒ¼ãƒ ",
    "section": "",
    "text": "ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒ¼ã®ã€Œ[Analysis]ã€ã¾ãŸã¯ã€Œ[Pythonåˆ†æ]ã€ã‹ã‚‰ã€å„åˆ†æãƒ¬ãƒãƒ¼ãƒˆã®ã‚«ãƒ¼ãƒ‰å½¢å¼ã®ãƒªã‚¹ãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚å„ãƒ¬ãƒãƒ¼ãƒˆã¯ç‹¬ç«‹ã—ãŸãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¨ã—ã¦ä½œæˆã•ã‚Œã¦ãŠã‚Šã€ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã“ã¨ã§ä¸­èº«ã‚’è©³ç´°ã«ç¢ºèªã§ãã¾ã™ã€‚\n\n\n\nSARIMAãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹åŒ»ç™‚è²»ãƒˆãƒ¬ãƒ³ãƒ‰äºˆæ¸¬\nåœ°åŸŸåˆ¥äººå£å‹•æ…‹ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸè¦å› åˆ†æ\nä¿é™ºè¨ºç™‚è²»ã¨è‡ªç”±è¨ºç™‚è²»ã®æ¯”è¼ƒåˆ†æ"
  },
  {
    "objectID": "demo.html",
    "href": "demo.html",
    "title": "å­¦ç¿’ã—ãŸã‚‚ã®ã‚’ã¾ã¨ã‚ã‚‹å ´æ‰€",
    "section": "",
    "text": "Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\n\nTitle\n\n\n\nAuthor\n\n\n\n\n\n\n\n\nÂ \n\n\nåŸºæœ¬çš„ãªå› å­åˆ†æã®ãƒ‡ãƒ¢\n\n\nÂ \n\n\n\n\n\n\nÂ \n\n\nSARIMAã‚’ä½¿ã£ãŸåŒ»ç™‚è²»äºˆæ¸¬ã®ãƒ‡ãƒ¢\n\n\nÂ \n\n\n\n\n\n\nÂ \n\n\nåŸºæœ¬çš„ãªå› å­åˆ†æã®ãƒ‡ãƒ¢\n\n\nÂ \n\n\n\n\n\n\nÂ \n\n\nSARIMAã‚’ä½¿ã£ãŸåŒ»ç™‚è²»äºˆæ¸¬ã®ãƒ‡ãƒ¢\n\n\nÂ \n\n\n\n\n\n\nÂ \n\n\nDataFrame and Plots ğŸ²ğŸ“Š\n\n\nÂ \n\n\n\n\n\n\nÂ \n\n\nInteractive presentation ğŸ“\n\n\nÂ \n\n\n\n\n\n\nÂ \n\n\nMercury demo ğŸ‘‹\n\n\nÂ \n\n\n\n\n\n\nDec 14, 2025\n\n\nUnderstanding the Basics of Markdown\n\n\nTako \n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "demo/understanding_mercury/sample/demo.html",
    "href": "demo/understanding_mercury/sample/demo.html",
    "title": "Mercury demo ğŸ‘‹",
    "section": "",
    "text": "import mercury as mr\napp = mr.App(title=\"Hello demo ğŸ‘‹\", description=\"Hello demo with Text widget\", show_code=True)\n\nShare your notebooks with everyone thanks to Mercury framework!\nPlease write your name in the left side bar and press Enter âŒ¨ï¸\nThe notebook will be automatically recomputed. Only cells with widget definition and below are recomputed. Thatâ€™s why it is fast!\nYou can download executed notebook as HTML or PDF (just click in the left side bar).\nYou can edit this notebook in the Jupyter Notebook, and changes will appear instantly in the Mercury.\n\nname = mr.Text(label=\"What is you name?\", value=\"Piotr\")\n\n\nmr.Markdown(f\"\"\"## Hello {name.value}! \n\nFor more examples please check our documentation at &lt;a href=\"https://runmercury.com\" target=\"_blank\"&gt;RunMercury.com&lt;a&gt; ğŸ“š\n\"\"\")"
  },
  {
    "objectID": "demo/understanding_mercury/sample/demo-dataframe-and-plots.html",
    "href": "demo/understanding_mercury/sample/demo-dataframe-and-plots.html",
    "title": "DataFrame and Plots ğŸ²ğŸ“Š",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport mercury as mr\n# control app with App class\napp = mr.App(title=\"DataFrame & Plots ğŸš€\", description=\"Showcase of Mercury Widgets\", show_code = False)\nShare your notebooks with everyone thanks to Mercury framework.\nPlease change number of samples and number of features in the left side bar. Notebook will be recomputed after widget change.\nsamples = mr.Slider(label=\"Number of samples\", min=50, max=100, value=75)\nfeatures = mr.Select(label=\"Number of features\", choices=[\"5\", \"10\", \"15\"], value=\"10\")\ndata = {}\nfor i in range(int(features.value)):\n    data[f\"Feature {i}\"] = np.random.rand(samples.value)\ndf = pd.DataFrame(data)"
  },
  {
    "objectID": "demo/understanding_mercury/sample/demo-dataframe-and-plots.html#random-data",
    "href": "demo/understanding_mercury/sample/demo-dataframe-and-plots.html#random-data",
    "title": "DataFrame and Plots ğŸ²ğŸ“Š",
    "section": "Random data ğŸ²",
    "text": "Random data ğŸ²\n\ndf"
  },
  {
    "objectID": "demo/understanding_mercury/sample/demo-dataframe-and-plots.html#scatter-plot",
    "href": "demo/understanding_mercury/sample/demo-dataframe-and-plots.html#scatter-plot",
    "title": "DataFrame and Plots ğŸ²ğŸ“Š",
    "section": "Scatter plot ğŸ“ˆ",
    "text": "Scatter plot ğŸ“ˆ\n\n_ = plt.plot(df[\"Feature 1\"], df[\"Feature 2\"], '*')"
  },
  {
    "objectID": "demo/understanding_mercury/sample/demo-dataframe-and-plots.html#random-data-histogram",
    "href": "demo/understanding_mercury/sample/demo-dataframe-and-plots.html#random-data-histogram",
    "title": "DataFrame and Plots ğŸ²ğŸ“Š",
    "section": "Random data histogram ğŸ“Š",
    "text": "Random data histogram ğŸ“Š\n\n_ = plt.hist(df[\"Feature 1\"], bins=40)"
  },
  {
    "objectID": "demo/understanding_mercury/mine/factor_analyze_demo.html",
    "href": "demo/understanding_mercury/mine/factor_analyze_demo.html",
    "title": "åŸºæœ¬çš„ãªå› å­åˆ†æã®ãƒ‡ãƒ¢",
    "section": "",
    "text": "import mercury as mr\napp = mr.App(title=\"demo analysis\") \n\nMercury ApplicationThis output won't appear in the web app.\n\n\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom factor_analyzer import FactorAnalyzer\nfrom factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\nfrom factor_analyzer.factor_analyzer import calculate_kmo\n\n# ã‚°ãƒ©ãƒ•ã®ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š\nsns.set(style='whitegrid')\n# æ³¨æ„: æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã¯ç’°å¢ƒã«åˆã‚ã›ã¦èª¿æ•´ã—ã¦ãã ã•ã„ï¼ˆColabã®å ´åˆã¯åˆ¥é€”ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ï¼‰\n# ã“ã“ã§ã¯è‹±èªãƒ©ãƒ™ãƒ«ã§é€²è¡Œã—ã¾ã™ãŒã€æ„å‘³ã¯è§£èª¬ã—ã¾ã™ã€‚\n\n\nãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ\nå› å­åˆ†æãŒç¶ºéº—ã«æ±ºã¾ã‚‹ã‚ˆã†ã€æ„å›³çš„ã«ç›¸é–¢ã‚’æŒãŸã›ãŸå¥è¨ºãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¾ã™ã€‚\nã“ã“ã§ã¯2ã¤ã®æ½œåœ¨å› å­ï¼ˆ1. ä»£è¬ãƒ»é‹å‹•ä¸è¶³å› å­ã€2. ã‚¹ãƒˆãƒ¬ã‚¹ãƒ»è¡€åœ§å› å­ï¼‰ã‚’æƒ³å®šã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™ã€‚\n\n# ä¹±æ•°ã‚·ãƒ¼ãƒ‰ã®å›ºå®š\nnp.random.seed(42)\nn_samples = 500\n\n# æ½œåœ¨å¤‰æ•°ï¼ˆçœŸã®è¦å› ï¼‰ã‚’ä½œæˆ\n# Factor 1: é‹å‹•ä¸è¶³ãƒ»è‚¥æº€å‚¾å‘ (Metabolic)\nf_metabolic = np.random.normal(0, 1, n_samples)\n# Factor 2: ã‚¹ãƒˆãƒ¬ã‚¹ãƒ»äº¤æ„Ÿç¥çµŒç·Šå¼µ (Stress)\nf_stress = np.random.normal(0, 1, n_samples)\n\n# è¦³æ¸¬å¤‰æ•°ï¼ˆå¥è¨ºé …ç›®ï¼‰ã‚’ä½œæˆ\n# å¼: è¦³æ¸¬å€¤ = è² è·é‡ * å› å­ + ãƒã‚¤ã‚º\ndata = {\n    # --- å› å­1ï¼ˆä»£è¬ãƒ»è‚¥æº€ï¼‰ã®å½±éŸ¿ãŒå¼·ã„é …ç›® ---\n    'BMI': 0.8 * f_metabolic + 0.1 * f_stress + np.random.normal(0, 0.5, n_samples),\n    'è…¹å›²(Waist)': 0.85 * f_metabolic + 0.1 * f_stress + np.random.normal(0, 0.5, n_samples),\n    'ä¸­æ€§è„‚è‚ª(TG)': 0.7 * f_metabolic + 0.2 * f_stress + np.random.normal(0, 0.6, n_samples),\n    'ç©ºè…¹æ™‚è¡€ç³–(FPG)': 0.6 * f_metabolic + 0.3 * f_stress + np.random.normal(0, 0.6, n_samples),\n    'HDLã‚³ãƒ¬ã‚¹ãƒ†ãƒ­ãƒ¼ãƒ«': -0.7 * f_metabolic + np.random.normal(0, 0.6, n_samples), # é€†ç›¸é–¢\n\n    # --- å› å­2ï¼ˆã‚¹ãƒˆãƒ¬ã‚¹ãƒ»è¡€åœ§ï¼‰ã®å½±éŸ¿ãŒå¼·ã„é …ç›® ---\n    'åç¸®æœŸè¡€åœ§(SBP)': 0.2 * f_metabolic + 0.85 * f_stress + np.random.normal(0, 0.5, n_samples),\n    'æ‹¡å¼µæœŸè¡€åœ§(DBP)': 0.2 * f_metabolic + 0.80 * f_stress + np.random.normal(0, 0.5, n_samples),\n    'è„ˆæ‹(Pulse)': 0.1 * f_metabolic + 0.6 * f_stress + np.random.normal(0, 0.7, n_samples),\n}\n\ndf = pd.DataFrame(data)\n\n# ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª\nprint(\"ãƒ‡ãƒ¼ã‚¿ã®ç›¸é–¢è¡Œåˆ—ï¼ˆä¸€éƒ¨ï¼‰:\")\ndisplay(df.corr().round(2))\n\nãƒ‡ãƒ¼ã‚¿ã®ç›¸é–¢è¡Œåˆ—ï¼ˆä¸€éƒ¨ï¼‰:\n\n\n\n\n\n\n\n\n\nBMI\nè…¹å›²(Waist)\nä¸­æ€§è„‚è‚ª(TG)\nç©ºè…¹æ™‚è¡€ç³–(FPG)\nHDLã‚³ãƒ¬ã‚¹ãƒ†ãƒ­ãƒ¼ãƒ«\nåç¸®æœŸè¡€åœ§(SBP)\næ‹¡å¼µæœŸè¡€åœ§(DBP)\nè„ˆæ‹(Pulse)\n\n\n\n\nBMI\n1.00\n0.72\n0.62\n0.59\n-0.63\n0.21\n0.20\n0.16\n\n\nè…¹å›²(Waist)\n0.72\n1.00\n0.63\n0.60\n-0.64\n0.19\n0.18\n0.13\n\n\nä¸­æ€§è„‚è‚ª(TG)\n0.62\n0.63\n1.00\n0.55\n-0.52\n0.32\n0.30\n0.20\n\n\nç©ºè…¹æ™‚è¡€ç³–(FPG)\n0.59\n0.60\n0.55\n1.00\n-0.50\n0.40\n0.35\n0.28\n\n\nHDLã‚³ãƒ¬ã‚¹ãƒ†ãƒ­ãƒ¼ãƒ«\n-0.63\n-0.64\n-0.52\n-0.50\n1.00\n-0.11\n-0.07\n-0.05\n\n\nåç¸®æœŸè¡€åœ§(SBP)\n0.21\n0.19\n0.32\n0.40\n-0.11\n1.00\n0.74\n0.56\n\n\næ‹¡å¼µæœŸè¡€åœ§(DBP)\n0.20\n0.18\n0.30\n0.35\n-0.07\n0.74\n1.00\n0.53\n\n\nè„ˆæ‹(Pulse)\n0.16\n0.13\n0.20\n0.28\n-0.05\n0.56\n0.53\n1.00\n\n\n\n\n\n\n\n\n\nå› å­åˆ†æã®äº‹å‰æ¤œå®š\nãƒ‡ãƒ¼ã‚¿ãŒå› å­åˆ†æã«é©ã—ã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã—ã¾ã™ï¼ˆKMOæ¤œå®šã¨ãƒãƒ¼ãƒˆãƒ¬ãƒƒãƒˆæ¤œå®šï¼‰\n\n# 1. ãƒãƒ¼ãƒˆãƒ¬ãƒƒãƒˆã®çƒé¢æ€§æ¤œå®š\n# på€¤ãŒ0.05æœªæº€ãªã‚‰ã€ç›¸é–¢è¡Œåˆ—ã¯å˜ä½è¡Œåˆ—ã§ã¯ãªã„ï¼ˆå› å­åˆ†æã™ã‚‹æ„å‘³ãŒã‚ã‚‹ï¼‰\nchi_square_value, p_value = calculate_bartlett_sphericity(df)\nprint(f\"Bartlett's test p-value: {p_value:.3e}\")\n\n# 2. KMO (Kaiser-Meyer-Olkin) æ¤œå®š\n# 0.6ä»¥ä¸Šã§ã‚ã‚Œã°å› å­åˆ†æã«é©ã—ã¦ã„ã‚‹ã¨ã•ã‚Œã‚‹\nkmo_all, kmo_model = calculate_kmo(df)\nprint(f\"KMO Test Value: {kmo_model:.3f}\")\n\nif kmo_model &gt; 0.6 and p_value &lt; 0.05:\n    print(\"&gt;&gt; åˆ¤å®š: ã“ã®ãƒ‡ãƒ¼ã‚¿ã¯å› å­åˆ†æã«é©ã—ã¦ã„ã¾ã™ã€‚\")\nelse:\n    print(\"&gt;&gt; åˆ¤å®š: ãƒ‡ãƒ¼ã‚¿ã‚’è¦‹ç›´ã™å¿…è¦ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚\")\n\nBartlett's test p-value: 0.000e+00\nKMO Test Value: 0.846\n&gt;&gt; åˆ¤å®š: ã“ã®ãƒ‡ãƒ¼ã‚¿ã¯å› å­åˆ†æã«é©ã—ã¦ã„ã¾ã™ã€‚\n\n\n\n\nå› å­ã®æ•°ã‚’æ±ºã‚ã‚‹ï¼ˆã‚¹ã‚¯ãƒªãƒ¼ãƒ—ãƒ­ãƒƒãƒˆï¼‰\nå›ºæœ‰å€¤ã‚’è¨ˆç®—ã—ã€ã„ãã¤ã®å› å­ã‚’æŠ½å‡ºãƒ»ä¿æŒã™ã¹ãã‹ã‚’ã‚°ãƒ©ãƒ•ã§ç¢ºèªã—ã¾ã™ã€‚\n\n# å› å­æ•°ã‚’å¤‰æ•°ã®æ•°ã ã‘è¨­å®šã—ã¦ä»®å®Ÿè¡Œ\nfa = FactorAnalyzer(n_factors=len(df.columns), rotation=None)\nfa.fit(df)\n\n# å›ºæœ‰å€¤ï¼ˆEigenvaluesï¼‰ã®å–å¾—\nev, v = fa.get_eigenvalues()\n\n# ã‚¹ã‚¯ãƒªãƒ¼ãƒ—ãƒ­ãƒƒãƒˆã®æç”»\nplt.figure(figsize=(8, 5))\nplt.scatter(range(1, df.shape[1]+1), ev)\nplt.plot(range(1, df.shape[1]+1), ev)\nplt.title('Scree Plot')\nplt.xlabel('Number of Factors')\nplt.ylabel('Eigenvalue')\nplt.axhline(y=1, color='r', linestyle='--') # åŸºæº–ç·šï¼ˆå›ºæœ‰å€¤1ä»¥ä¸Šã‚’æ¡ç”¨ã™ã‚‹ã“ã¨ãŒå¤šã„ï¼‰\nplt.grid(True)\nplt.show()\n\nprint(\"å›ºæœ‰å€¤:\", ev.round(2))\n# é€šå¸¸ã€å›ºæœ‰å€¤ãŒæ€¥æ¿€ã«ä¸‹ãŒã£ã¦ãªã ã‚‰ã‹ã«ãªã‚‹ç›´å‰ã€ã¾ãŸã¯1ä»¥ä¸Šã®æ•°ã‚’é¸ã³ã¾ã™ã€‚\n# ä»Šå›ã®è¨­è¨ˆã§ã¯ã€Œ2ã€ã¾ãŸã¯ã€Œ3ã€ã‚ãŸã‚Šã§æŠ˜ã‚Œã‚‹ã¯ãšã§ã™ã€‚\n\n\n\n\n\n\n\n\nå›ºæœ‰å€¤: [3.83 1.89 0.53 0.44 0.43 0.35 0.28 0.25]\n\n\n\n\nå› å­åˆ†æã®å®Ÿè¡Œã¨ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—å¯è¦–åŒ–\nå› å­æ•°ã‚’ã€Œ2ã€ã¨ä»®å®šã—ã¦å®Ÿè¡Œã—ã¾ã™ã€‚ å›è»¢æ³•ã«ã¯ promaxï¼ˆæ–œäº¤å›è»¢ï¼‰ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã“ã‚Œã¯ã€å¥åº·è¦å› åŒå£«ï¼ˆè‚¥æº€ã¨ã‚¹ãƒˆãƒ¬ã‚¹ï¼‰ã«ã¯ç›¸é–¢ãŒã‚ã‚‹ã“ã¨ãŒè‡ªç„¶ã ã‹ã‚‰ã§ã™ã€‚\n\nimport plotly.express as px\n\n# --- åˆ†æãƒ‘ãƒ¼ãƒˆï¼ˆå‰å›ã¨åŒã˜ï¼‰---\n# å› å­ã®æ•°ã‚’æŒ‡å®šï¼ˆã‚¹ã‚¯ãƒªãƒ¼ãƒ—ãƒ­ãƒƒãƒˆã®çµæœã‚’è¦‹ã¦ 2 ã¨ä»®å®šï¼‰\nn_factors = 2\n\n# å› å­åˆ†æã®å®Ÿè¡Œ (promaxå›è»¢)\nfa = FactorAnalyzer(n_factors=n_factors, rotation='promax')\nfa.fit(df)\n\n# å› å­è² è·é‡ï¼ˆFactor Loadingsï¼‰ã®å–å¾—\nloadings = pd.DataFrame(fa.loadings_, \n                        index=df.columns, \n                        columns=[f'Factor{i+1}' for i in range(n_factors)])\n\n# --- å¯è¦–åŒ–ãƒ‘ãƒ¼ãƒˆ (Plotly) ---\nfig_heatmap = px.imshow(\n    loadings,\n    text_auto='.2f',  # å€¤ã‚’å°æ•°ç‚¹2æ¡ã§è¡¨ç¤º\n    aspect=\"auto\",\n    color_continuous_scale='RdBu_r', # èµ¤ã€œé’ï¼ˆç›¸é–¢ã®æ­£è² ã‚’è¡¨ç¾ï¼‰\n    zmin=-1, zmax=1,\n    title='Factor Loadings (å› å­è² è·é‡)'\n)\n\nfig_heatmap.update_layout(\n    xaxis_title=\"Factors\",\n    yaxis_title=\"Variables\",\n    width=600,\n    height=600\n)\n\nfig_heatmap.show()\n\n# å› å­ã®è§£é‡ˆãƒ’ãƒ³ãƒˆ\nprint(\"--- å› å­ã®è§£é‡ˆ ---\")\nprint(\"èµ¤è‰²ãŒå¼·ã„ç®‡æ‰€ = ãã®å› å­ã¨ã®æ­£ã®ç›¸é–¢ãŒå¼·ã„\")\nprint(\"é’è‰²ãŒå¼·ã„ç®‡æ‰€ = ãã®å› å­ã¨ã®è² ã®ç›¸é–¢ãŒå¼·ã„\")\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n--- å› å­ã®è§£é‡ˆ ---\nèµ¤è‰²ãŒå¼·ã„ç®‡æ‰€ = ãã®å› å­ã¨ã®æ­£ã®ç›¸é–¢ãŒå¼·ã„\né’è‰²ãŒå¼·ã„ç®‡æ‰€ = ãã®å› å­ã¨ã®è² ã®ç›¸é–¢ãŒå¼·ã„\n\n\n\n\nå› å­å¾—ç‚¹ã®ç®—å‡ºï¼ˆå€‹äººã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼‰\n\nimport plotly.graph_objects as go\n\n# --- è¨ˆç®—ãƒ‘ãƒ¼ãƒˆ ---\n# å› å­å¾—ç‚¹ã®è¨ˆç®—\nfactor_scores = pd.DataFrame(fa.transform(df), \n                            columns=[f'Factor{i+1}' for i in range(n_factors)])\n\n# å…ƒãƒ‡ãƒ¼ã‚¿ã¨çµåˆ\nresult_df = pd.concat([df, factor_scores], axis=1)\n\n# å› å­ã®å‘½åï¼ˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®çµæœã‚’è¦‹ã¦é©å®œå¤‰æ›´ã—ã¦ãã ã•ã„ï¼‰\n# ã“ã“ã§ã¯ Factor1=ä»£è¬ãƒªã‚¹ã‚¯, Factor2=ã‚¹ãƒˆãƒ¬ã‚¹ãƒ»è¡€åœ§ãƒªã‚¹ã‚¯ ã¨ä»®å®š\nx_axis_label = 'Score_Metabolic(é‹å‹•ä¸è¶³)'\ny_axis_label = 'Score_Stress(é«˜è¡€åœ§è² è·)'\n\nresult_df = result_df.rename(columns={\n    'Factor1': x_axis_label,\n    'Factor2': y_axis_label\n})\n\n# --- å¯è¦–åŒ–ãƒ‘ãƒ¼ãƒˆ (Plotly) ---\nfig_scatter = px.scatter(\n    result_df, \n    x=x_axis_label, \n    y=y_axis_label,\n    # ãƒ›ãƒãƒ¼ã—ãŸæ™‚ã«å…ƒã®å¥è¨ºãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºï¼ˆåˆ†æã«ä¾¿åˆ©ï¼ï¼‰\n    hover_data=['BMI', 'åç¸®æœŸè¡€åœ§(SBP)', 'ç©ºè…¹æ™‚è¡€ç³–(FPG)'], \n    title='å—è¨ºè€…ã®å› å­ã‚¹ã‚³ã‚¢åˆ†å¸ƒï¼ˆãƒªã‚¹ã‚¯ãƒãƒƒãƒ—ï¼‰',\n    opacity=0.7\n)\n\n# ä¸­å¿ƒç·šï¼ˆ0,0ï¼‰ã‚’è¿½åŠ ã—ã¦è±¡é™ã‚’ã‚ã‹ã‚Šã‚„ã™ãã™ã‚‹\nfig_scatter.add_vline(x=0, line_width=1, line_dash=\"dash\", line_color=\"gray\")\nfig_scatter.add_hline(y=0, line_width=1, line_dash=\"dash\", line_color=\"gray\")\n\n# ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´\nfig_scatter.update_layout(\n    xaxis_title=x_axis_label,\n    yaxis_title=y_axis_label,\n    width=800,\n    height=600,\n    template='plotly_white'\n)\n\n# è±¡é™ã®æ³¨é‡ˆï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰\nfig_scatter.add_annotation(x=2, y=2, text=\"é«˜ãƒªã‚¹ã‚¯ç¾¤\", showarrow=False, font=dict(color=\"red\"))\nfig_scatter.add_annotation(x=-2, y=-2, text=\"å¥åº·ç¾¤\", showarrow=False, font=dict(color=\"green\"))\n\nfig_scatter.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\nãƒãƒ¼ãƒˆ\n\nå› å­è² è·é‡ (Loading): å¤‰æ•°ã¨å› å­ã®ç›¸é–¢ä¿‚æ•°ã®ã‚ˆã†ãªã‚‚ã®ã€‚çµ¶å¯¾å€¤ãŒ0.4ä»¥ä¸Šã‚ã‚Œã°é–¢ä¿‚ãŒå¼·ã„ã¨è¦‹ãªã—ã¾ã™ã€‚\nå›è»¢ (Rotation): promax ã¯æ–œäº¤å›è»¢ã§ã€å› å­é–“ã®ç›¸é–¢ã‚’è¨±å®¹ã—ã¾ã™ï¼ˆç¾å®Ÿçš„ï¼‰ã€‚varimax ã¯ç›´äº¤å›è»¢ã§ã€å› å­é–“ãŒç„¡ç›¸é–¢ã§ã‚ã‚‹ã¨ä»®å®šã—ã¾ã™ã€‚\nè§£é‡ˆ: å‡ºåŠ›ã•ã‚ŒãŸãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’è¦‹ã¦ã€ã€Œå› å­1ã¯BMIã¨è¡€ç³–å€¤ãŒé«˜ã„ã‹ã‚‰ã€ãƒ¡ã‚¿ãƒœå› å­ã€ã ãªã€ã¨äººé–“ãŒæ„å‘³ä»˜ã‘ã‚’è¡Œã„ã¾ã™ã€‚"
  },
  {
    "objectID": "demo/basic_factor_analyze/factor_analyze_demo.html",
    "href": "demo/basic_factor_analyze/factor_analyze_demo.html",
    "title": "åŸºæœ¬çš„ãªå› å­åˆ†æã®ãƒ‡ãƒ¢",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom factor_analyzer import FactorAnalyzer\nfrom factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\nfrom factor_analyzer.factor_analyzer import calculate_kmo\n\n# ã‚°ãƒ©ãƒ•ã®ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š\nsns.set(style='whitegrid')\n# æ³¨æ„: æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã¯ç’°å¢ƒã«åˆã‚ã›ã¦èª¿æ•´ã—ã¦ãã ã•ã„ï¼ˆColabã®å ´åˆã¯åˆ¥é€”ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ï¼‰\n# ã“ã“ã§ã¯è‹±èªãƒ©ãƒ™ãƒ«ã§é€²è¡Œã—ã¾ã™ãŒã€æ„å‘³ã¯è§£èª¬ã—ã¾ã™ã€‚\n\n\nãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ\nå› å­åˆ†æãŒç¶ºéº—ã«æ±ºã¾ã‚‹ã‚ˆã†ã€æ„å›³çš„ã«ç›¸é–¢ã‚’æŒãŸã›ãŸå¥è¨ºãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¾ã™ã€‚\nã“ã“ã§ã¯2ã¤ã®æ½œåœ¨å› å­ï¼ˆ1. ä»£è¬ãƒ»é‹å‹•ä¸è¶³å› å­ã€2. ã‚¹ãƒˆãƒ¬ã‚¹ãƒ»è¡€åœ§å› å­ï¼‰ã‚’æƒ³å®šã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™ã€‚\n\n# ä¹±æ•°ã‚·ãƒ¼ãƒ‰ã®å›ºå®š\nnp.random.seed(42)\nn_samples = 500\n\n# æ½œåœ¨å¤‰æ•°ï¼ˆçœŸã®è¦å› ï¼‰ã‚’ä½œæˆ\n# Factor 1: é‹å‹•ä¸è¶³ãƒ»è‚¥æº€å‚¾å‘ (Metabolic)\nf_metabolic = np.random.normal(0, 1, n_samples)\n# Factor 2: ã‚¹ãƒˆãƒ¬ã‚¹ãƒ»äº¤æ„Ÿç¥çµŒç·Šå¼µ (Stress)\nf_stress = np.random.normal(0, 1, n_samples)\n\n# è¦³æ¸¬å¤‰æ•°ï¼ˆå¥è¨ºé …ç›®ï¼‰ã‚’ä½œæˆ\n# å¼: è¦³æ¸¬å€¤ = è² è·é‡ * å› å­ + ãƒã‚¤ã‚º\ndata = {\n    # --- å› å­1ï¼ˆä»£è¬ãƒ»è‚¥æº€ï¼‰ã®å½±éŸ¿ãŒå¼·ã„é …ç›® ---\n    'BMI': 0.8 * f_metabolic + 0.1 * f_stress + np.random.normal(0, 0.5, n_samples),\n    'è…¹å›²(Waist)': 0.85 * f_metabolic + 0.1 * f_stress + np.random.normal(0, 0.5, n_samples),\n    'ä¸­æ€§è„‚è‚ª(TG)': 0.7 * f_metabolic + 0.2 * f_stress + np.random.normal(0, 0.6, n_samples),\n    'ç©ºè…¹æ™‚è¡€ç³–(FPG)': 0.6 * f_metabolic + 0.3 * f_stress + np.random.normal(0, 0.6, n_samples),\n    'HDLã‚³ãƒ¬ã‚¹ãƒ†ãƒ­ãƒ¼ãƒ«': -0.7 * f_metabolic + np.random.normal(0, 0.6, n_samples), # é€†ç›¸é–¢\n\n    # --- å› å­2ï¼ˆã‚¹ãƒˆãƒ¬ã‚¹ãƒ»è¡€åœ§ï¼‰ã®å½±éŸ¿ãŒå¼·ã„é …ç›® ---\n    'åç¸®æœŸè¡€åœ§(SBP)': 0.2 * f_metabolic + 0.85 * f_stress + np.random.normal(0, 0.5, n_samples),\n    'æ‹¡å¼µæœŸè¡€åœ§(DBP)': 0.2 * f_metabolic + 0.80 * f_stress + np.random.normal(0, 0.5, n_samples),\n    'è„ˆæ‹(Pulse)': 0.1 * f_metabolic + 0.6 * f_stress + np.random.normal(0, 0.7, n_samples),\n}\n\ndf = pd.DataFrame(data)\n\n# ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª\nprint(\"ãƒ‡ãƒ¼ã‚¿ã®ç›¸é–¢è¡Œåˆ—ï¼ˆä¸€éƒ¨ï¼‰:\")\ndisplay(df.corr().round(2))\n\nãƒ‡ãƒ¼ã‚¿ã®ç›¸é–¢è¡Œåˆ—ï¼ˆä¸€éƒ¨ï¼‰:\n\n\n\n\n\n\n\n\n\nBMI\nè…¹å›²(Waist)\nä¸­æ€§è„‚è‚ª(TG)\nç©ºè…¹æ™‚è¡€ç³–(FPG)\nHDLã‚³ãƒ¬ã‚¹ãƒ†ãƒ­ãƒ¼ãƒ«\nåç¸®æœŸè¡€åœ§(SBP)\næ‹¡å¼µæœŸè¡€åœ§(DBP)\nè„ˆæ‹(Pulse)\n\n\n\n\nBMI\n1.00\n0.72\n0.62\n0.59\n-0.63\n0.21\n0.20\n0.16\n\n\nè…¹å›²(Waist)\n0.72\n1.00\n0.63\n0.60\n-0.64\n0.19\n0.18\n0.13\n\n\nä¸­æ€§è„‚è‚ª(TG)\n0.62\n0.63\n1.00\n0.55\n-0.52\n0.32\n0.30\n0.20\n\n\nç©ºè…¹æ™‚è¡€ç³–(FPG)\n0.59\n0.60\n0.55\n1.00\n-0.50\n0.40\n0.35\n0.28\n\n\nHDLã‚³ãƒ¬ã‚¹ãƒ†ãƒ­ãƒ¼ãƒ«\n-0.63\n-0.64\n-0.52\n-0.50\n1.00\n-0.11\n-0.07\n-0.05\n\n\nåç¸®æœŸè¡€åœ§(SBP)\n0.21\n0.19\n0.32\n0.40\n-0.11\n1.00\n0.74\n0.56\n\n\næ‹¡å¼µæœŸè¡€åœ§(DBP)\n0.20\n0.18\n0.30\n0.35\n-0.07\n0.74\n1.00\n0.53\n\n\nè„ˆæ‹(Pulse)\n0.16\n0.13\n0.20\n0.28\n-0.05\n0.56\n0.53\n1.00\n\n\n\n\n\n\n\n\n\nå› å­åˆ†æã®äº‹å‰æ¤œå®š\nãƒ‡ãƒ¼ã‚¿ãŒå› å­åˆ†æã«é©ã—ã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã—ã¾ã™ï¼ˆKMOæ¤œå®šã¨ãƒãƒ¼ãƒˆãƒ¬ãƒƒãƒˆæ¤œå®šï¼‰\n\n# 1. ãƒãƒ¼ãƒˆãƒ¬ãƒƒãƒˆã®çƒé¢æ€§æ¤œå®š\n# på€¤ãŒ0.05æœªæº€ãªã‚‰ã€ç›¸é–¢è¡Œåˆ—ã¯å˜ä½è¡Œåˆ—ã§ã¯ãªã„ï¼ˆå› å­åˆ†æã™ã‚‹æ„å‘³ãŒã‚ã‚‹ï¼‰\nchi_square_value, p_value = calculate_bartlett_sphericity(df)\nprint(f\"Bartlett's test p-value: {p_value:.3e}\")\n\n# 2. KMO (Kaiser-Meyer-Olkin) æ¤œå®š\n# 0.6ä»¥ä¸Šã§ã‚ã‚Œã°å› å­åˆ†æã«é©ã—ã¦ã„ã‚‹ã¨ã•ã‚Œã‚‹\nkmo_all, kmo_model = calculate_kmo(df)\nprint(f\"KMO Test Value: {kmo_model:.3f}\")\n\nif kmo_model &gt; 0.6 and p_value &lt; 0.05:\n    print(\"&gt;&gt; åˆ¤å®š: ã“ã®ãƒ‡ãƒ¼ã‚¿ã¯å› å­åˆ†æã«é©ã—ã¦ã„ã¾ã™ã€‚\")\nelse:\n    print(\"&gt;&gt; åˆ¤å®š: ãƒ‡ãƒ¼ã‚¿ã‚’è¦‹ç›´ã™å¿…è¦ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚\")\n\nBartlett's test p-value: 0.000e+00\nKMO Test Value: 0.846\n&gt;&gt; åˆ¤å®š: ã“ã®ãƒ‡ãƒ¼ã‚¿ã¯å› å­åˆ†æã«é©ã—ã¦ã„ã¾ã™ã€‚\n\n\n\n\nå› å­ã®æ•°ã‚’æ±ºã‚ã‚‹ï¼ˆã‚¹ã‚¯ãƒªãƒ¼ãƒ—ãƒ­ãƒƒãƒˆï¼‰\nå›ºæœ‰å€¤ã‚’è¨ˆç®—ã—ã€ã„ãã¤ã®å› å­ã‚’æŠ½å‡ºãƒ»ä¿æŒã™ã¹ãã‹ã‚’ã‚°ãƒ©ãƒ•ã§ç¢ºèªã—ã¾ã™ã€‚\n\n# å› å­æ•°ã‚’å¤‰æ•°ã®æ•°ã ã‘è¨­å®šã—ã¦ä»®å®Ÿè¡Œ\nfa = FactorAnalyzer(n_factors=len(df.columns), rotation=None)\nfa.fit(df)\n\n# å›ºæœ‰å€¤ï¼ˆEigenvaluesï¼‰ã®å–å¾—\nev, v = fa.get_eigenvalues()\n\n# ã‚¹ã‚¯ãƒªãƒ¼ãƒ—ãƒ­ãƒƒãƒˆã®æç”»\nplt.figure(figsize=(8, 5))\nplt.scatter(range(1, df.shape[1]+1), ev)\nplt.plot(range(1, df.shape[1]+1), ev)\nplt.title('Scree Plot')\nplt.xlabel('Number of Factors')\nplt.ylabel('Eigenvalue')\nplt.axhline(y=1, color='r', linestyle='--') # åŸºæº–ç·šï¼ˆå›ºæœ‰å€¤1ä»¥ä¸Šã‚’æ¡ç”¨ã™ã‚‹ã“ã¨ãŒå¤šã„ï¼‰\nplt.grid(True)\nplt.show()\n\nprint(\"å›ºæœ‰å€¤:\", ev.round(2))\n# é€šå¸¸ã€å›ºæœ‰å€¤ãŒæ€¥æ¿€ã«ä¸‹ãŒã£ã¦ãªã ã‚‰ã‹ã«ãªã‚‹ç›´å‰ã€ã¾ãŸã¯1ä»¥ä¸Šã®æ•°ã‚’é¸ã³ã¾ã™ã€‚\n# ä»Šå›ã®è¨­è¨ˆã§ã¯ã€Œ2ã€ã¾ãŸã¯ã€Œ3ã€ã‚ãŸã‚Šã§æŠ˜ã‚Œã‚‹ã¯ãšã§ã™ã€‚\n\n\n\n\n\n\n\n\nå›ºæœ‰å€¤: [3.83 1.89 0.53 0.44 0.43 0.35 0.28 0.25]\n\n\n\n\nå› å­åˆ†æã®å®Ÿè¡Œã¨ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—å¯è¦–åŒ–\nå› å­æ•°ã‚’ã€Œ2ã€ã¨ä»®å®šã—ã¦å®Ÿè¡Œã—ã¾ã™ã€‚ å›è»¢æ³•ã«ã¯ promaxï¼ˆæ–œäº¤å›è»¢ï¼‰ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã“ã‚Œã¯ã€å¥åº·è¦å› åŒå£«ï¼ˆè‚¥æº€ã¨ã‚¹ãƒˆãƒ¬ã‚¹ï¼‰ã«ã¯ç›¸é–¢ãŒã‚ã‚‹ã“ã¨ãŒè‡ªç„¶ã ã‹ã‚‰ã§ã™ã€‚\n\nimport plotly.express as px\n\n# --- åˆ†æãƒ‘ãƒ¼ãƒˆï¼ˆå‰å›ã¨åŒã˜ï¼‰---\n# å› å­ã®æ•°ã‚’æŒ‡å®šï¼ˆã‚¹ã‚¯ãƒªãƒ¼ãƒ—ãƒ­ãƒƒãƒˆã®çµæœã‚’è¦‹ã¦ 2 ã¨ä»®å®šï¼‰\nn_factors = 2\n\n# å› å­åˆ†æã®å®Ÿè¡Œ (promaxå›è»¢)\nfa = FactorAnalyzer(n_factors=n_factors, rotation='promax')\nfa.fit(df)\n\n# å› å­è² è·é‡ï¼ˆFactor Loadingsï¼‰ã®å–å¾—\nloadings = pd.DataFrame(fa.loadings_, \n                        index=df.columns, \n                        columns=[f'Factor{i+1}' for i in range(n_factors)])\n\n# --- å¯è¦–åŒ–ãƒ‘ãƒ¼ãƒˆ (Plotly) ---\nfig_heatmap = px.imshow(\n    loadings,\n    text_auto='.2f',  # å€¤ã‚’å°æ•°ç‚¹2æ¡ã§è¡¨ç¤º\n    aspect=\"auto\",\n    color_continuous_scale='RdBu_r', # èµ¤ã€œé’ï¼ˆç›¸é–¢ã®æ­£è² ã‚’è¡¨ç¾ï¼‰\n    zmin=-1, zmax=1,\n    title='Factor Loadings (å› å­è² è·é‡)'\n)\n\nfig_heatmap.update_layout(\n    xaxis_title=\"Factors\",\n    yaxis_title=\"Variables\",\n    width=600,\n    height=600\n)\n\nfig_heatmap.show()\n\n# å› å­ã®è§£é‡ˆãƒ’ãƒ³ãƒˆ\nprint(\"--- å› å­ã®è§£é‡ˆ ---\")\nprint(\"èµ¤è‰²ãŒå¼·ã„ç®‡æ‰€ = ãã®å› å­ã¨ã®æ­£ã®ç›¸é–¢ãŒå¼·ã„\")\nprint(\"é’è‰²ãŒå¼·ã„ç®‡æ‰€ = ãã®å› å­ã¨ã®è² ã®ç›¸é–¢ãŒå¼·ã„\")\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n--- å› å­ã®è§£é‡ˆ ---\nèµ¤è‰²ãŒå¼·ã„ç®‡æ‰€ = ãã®å› å­ã¨ã®æ­£ã®ç›¸é–¢ãŒå¼·ã„\né’è‰²ãŒå¼·ã„ç®‡æ‰€ = ãã®å› å­ã¨ã®è² ã®ç›¸é–¢ãŒå¼·ã„\n\n\n\n\nå› å­å¾—ç‚¹ã®ç®—å‡ºï¼ˆå€‹äººã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼‰\n\nimport plotly.graph_objects as go\n\n# --- è¨ˆç®—ãƒ‘ãƒ¼ãƒˆ ---\n# å› å­å¾—ç‚¹ã®è¨ˆç®—\nfactor_scores = pd.DataFrame(fa.transform(df), \n                            columns=[f'Factor{i+1}' for i in range(n_factors)])\n\n# å…ƒãƒ‡ãƒ¼ã‚¿ã¨çµåˆ\nresult_df = pd.concat([df, factor_scores], axis=1)\n\n# å› å­ã®å‘½åï¼ˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®çµæœã‚’è¦‹ã¦é©å®œå¤‰æ›´ã—ã¦ãã ã•ã„ï¼‰\n# ã“ã“ã§ã¯ Factor1=ä»£è¬ãƒªã‚¹ã‚¯, Factor2=ã‚¹ãƒˆãƒ¬ã‚¹ãƒ»è¡€åœ§ãƒªã‚¹ã‚¯ ã¨ä»®å®š\nx_axis_label = 'Score_Metabolic(é‹å‹•ä¸è¶³)'\ny_axis_label = 'Score_Stress(é«˜è¡€åœ§è² è·)'\n\nresult_df = result_df.rename(columns={\n    'Factor1': x_axis_label,\n    'Factor2': y_axis_label\n})\n\n# --- å¯è¦–åŒ–ãƒ‘ãƒ¼ãƒˆ (Plotly) ---\nfig_scatter = px.scatter(\n    result_df, \n    x=x_axis_label, \n    y=y_axis_label,\n    # ãƒ›ãƒãƒ¼ã—ãŸæ™‚ã«å…ƒã®å¥è¨ºãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºï¼ˆåˆ†æã«ä¾¿åˆ©ï¼ï¼‰\n    hover_data=['BMI', 'åç¸®æœŸè¡€åœ§(SBP)', 'ç©ºè…¹æ™‚è¡€ç³–(FPG)'], \n    title='å—è¨ºè€…ã®å› å­ã‚¹ã‚³ã‚¢åˆ†å¸ƒï¼ˆãƒªã‚¹ã‚¯ãƒãƒƒãƒ—ï¼‰',\n    opacity=0.7\n)\n\n# ä¸­å¿ƒç·šï¼ˆ0,0ï¼‰ã‚’è¿½åŠ ã—ã¦è±¡é™ã‚’ã‚ã‹ã‚Šã‚„ã™ãã™ã‚‹\nfig_scatter.add_vline(x=0, line_width=1, line_dash=\"dash\", line_color=\"gray\")\nfig_scatter.add_hline(y=0, line_width=1, line_dash=\"dash\", line_color=\"gray\")\n\n# ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´\nfig_scatter.update_layout(\n    xaxis_title=x_axis_label,\n    yaxis_title=y_axis_label,\n    width=800,\n    height=600,\n    template='plotly_white'\n)\n\n# è±¡é™ã®æ³¨é‡ˆï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰\nfig_scatter.add_annotation(x=2, y=2, text=\"é«˜ãƒªã‚¹ã‚¯ç¾¤\", showarrow=False, font=dict(color=\"red\"))\nfig_scatter.add_annotation(x=-2, y=-2, text=\"å¥åº·ç¾¤\", showarrow=False, font=dict(color=\"green\"))\n\nfig_scatter.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\nãƒãƒ¼ãƒˆ\n\nå› å­è² è·é‡ (Loading): å¤‰æ•°ã¨å› å­ã®ç›¸é–¢ä¿‚æ•°ã®ã‚ˆã†ãªã‚‚ã®ã€‚çµ¶å¯¾å€¤ãŒ0.4ä»¥ä¸Šã‚ã‚Œã°é–¢ä¿‚ãŒå¼·ã„ã¨è¦‹ãªã—ã¾ã™ã€‚\nå›è»¢ (Rotation): promax ã¯æ–œäº¤å›è»¢ã§ã€å› å­é–“ã®ç›¸é–¢ã‚’è¨±å®¹ã—ã¾ã™ï¼ˆç¾å®Ÿçš„ï¼‰ã€‚varimax ã¯ç›´äº¤å›è»¢ã§ã€å› å­é–“ãŒç„¡ç›¸é–¢ã§ã‚ã‚‹ã¨ä»®å®šã—ã¾ã™ã€‚\nè§£é‡ˆ: å‡ºåŠ›ã•ã‚ŒãŸãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’è¦‹ã¦ã€ã€Œå› å­1ã¯BMIã¨è¡€ç³–å€¤ãŒé«˜ã„ã‹ã‚‰ã€ãƒ¡ã‚¿ãƒœå› å­ã€ã ãªã€ã¨äººé–“ãŒæ„å‘³ä»˜ã‘ã‚’è¡Œã„ã¾ã™ã€‚"
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "åˆ†æãƒ¬ãƒãƒ¼ãƒˆä¸€è¦§",
    "section": "",
    "text": "Order By\n      Default\n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nAuthor\n\n\n\n\n\n\n\n\nÂ \n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Tako ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã¤ã„ã¦",
    "section": "",
    "text": "Tako (Time-series Analysis & Knowledge Organization) ã¯ã€è¤‡é›‘ãªæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰çŸ¥è¦‹ã‚’å¼•ãå‡ºã—ã€å†ç¾æ€§ã®é«˜ã„ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹ã“ã¨ã«ç‰¹åŒ–ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ãƒãƒ¼ãƒ ã§ã™ã€‚\nç§ãŸã¡ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³ã¯ã€åŒ»ç™‚è²»ã®ãƒˆãƒ¬ãƒ³ãƒ‰äºˆæ¸¬ã®ã‚ˆã†ã«ã€ç¤¾ä¼šçš„ã«é‡è¦ãªèª²é¡Œã«å¯¾ã—ã¦å®¢è¦³çš„ã‹ã¤ä¿¡é ¼ã§ãã‚‹äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’æä¾›ã™ã‚‹ã“ã¨ã§ã™ã€‚\n\n\n\næœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€ä»¥ä¸‹ã®æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã«åŸºã¥ã„ã¦æ§‹ç¯‰ã•ã‚Œã¦ãŠã‚Šã€ã™ã¹ã¦ã®åˆ†æãƒ—ãƒ­ã‚»ã‚¹ã«ãŠã„ã¦é€æ˜æ€§ã¨å†ç¾æ€§ã‚’ç¢ºä¿ã—ã¦ã„ã¾ã™ã€‚\n\n\n\n\n\n\n\n\nã‚«ãƒ†ã‚´ãƒª\nä¸»è¦æŠ€è¡“\nç›®çš„\n\n\n\n\nãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³\nQuarto\nãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã€ãƒ¬ãƒãƒ¼ãƒˆã€ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã®çµ±åˆç®¡ç†\n\n\næ™‚ç³»åˆ—è§£æ\nPython (Statsmodels, Scikit-learn)\nSARIMAã‚„çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸé«˜åº¦ãªäºˆæ¸¬\n\n\nå¯è¦–åŒ–\nPlotly, Matplotlib\nã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªã‚°ãƒ©ãƒ•ä½œæˆã¨é™çš„ãƒ—ãƒ­ãƒƒãƒˆ\n\n\nãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹\nPandas\nãƒ‡ãƒ¼ã‚¿å‡¦ç†ã€ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°\n\n\nãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†\nGit\nå…¨ã‚³ãƒ¼ãƒ‰ã®å±¥æ­´ç®¡ç†ã¨ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³\n\n\n\n\n\n\næœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚„åˆ†æå†…å®¹ã«é–¢ã™ã‚‹ã”è³ªå•ã€ã”ææ¡ˆãªã©ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã€ä»¥ä¸‹ã¾ã§ãŠæ°—è»½ã«ã”é€£çµ¡ãã ã•ã„ã€‚\n\nE-mail: contact@tako-data.jp (ä»®æƒ³)\nãƒªãƒã‚¸ãƒˆãƒª: [GitHubã¸ã®ãƒªãƒ³ã‚¯] (ã“ã®ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã¯ã“ã¡ã‚‰)\n\n\n\nã€ŒTakoã€ã¯ã€è§¦æ‰‹ã®ã‚ˆã†ã«å¤šè§’çš„ãªè¦–ç‚¹ã§ãƒ‡ãƒ¼ã‚¿ã«ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã—ã€çŸ¥è­˜ã‚’çµ„ç¹”åŒ–ï¼ˆOrganizationï¼‰ã™ã‚‹ã“ã¨ã‚’è±¡å¾´ã—ã¦ã„ã¾ã™ã€‚"
  },
  {
    "objectID": "about.html#ç§ãŸã¡ã«ã¤ã„ã¦",
    "href": "about.html#ç§ãŸã¡ã«ã¤ã„ã¦",
    "title": "Tako ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã¤ã„ã¦",
    "section": "",
    "text": "Tako (Time-series Analysis & Knowledge Organization) ã¯ã€è¤‡é›‘ãªæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰çŸ¥è¦‹ã‚’å¼•ãå‡ºã—ã€å†ç¾æ€§ã®é«˜ã„ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹ã“ã¨ã«ç‰¹åŒ–ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ãƒãƒ¼ãƒ ã§ã™ã€‚\nç§ãŸã¡ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³ã¯ã€åŒ»ç™‚è²»ã®ãƒˆãƒ¬ãƒ³ãƒ‰äºˆæ¸¬ã®ã‚ˆã†ã«ã€ç¤¾ä¼šçš„ã«é‡è¦ãªèª²é¡Œã«å¯¾ã—ã¦å®¢è¦³çš„ã‹ã¤ä¿¡é ¼ã§ãã‚‹äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’æä¾›ã™ã‚‹ã“ã¨ã§ã™ã€‚"
  },
  {
    "objectID": "about.html#ä½¿ç”¨æŠ€è¡“ã¨ç’°å¢ƒ",
    "href": "about.html#ä½¿ç”¨æŠ€è¡“ã¨ç’°å¢ƒ",
    "title": "Tako ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã¤ã„ã¦",
    "section": "",
    "text": "æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€ä»¥ä¸‹ã®æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã«åŸºã¥ã„ã¦æ§‹ç¯‰ã•ã‚Œã¦ãŠã‚Šã€ã™ã¹ã¦ã®åˆ†æãƒ—ãƒ­ã‚»ã‚¹ã«ãŠã„ã¦é€æ˜æ€§ã¨å†ç¾æ€§ã‚’ç¢ºä¿ã—ã¦ã„ã¾ã™ã€‚\n\n\n\n\n\n\n\n\nã‚«ãƒ†ã‚´ãƒª\nä¸»è¦æŠ€è¡“\nç›®çš„\n\n\n\n\nãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³\nQuarto\nãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã€ãƒ¬ãƒãƒ¼ãƒˆã€ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã®çµ±åˆç®¡ç†\n\n\næ™‚ç³»åˆ—è§£æ\nPython (Statsmodels, Scikit-learn)\nSARIMAã‚„çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸé«˜åº¦ãªäºˆæ¸¬\n\n\nå¯è¦–åŒ–\nPlotly, Matplotlib\nã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªã‚°ãƒ©ãƒ•ä½œæˆã¨é™çš„ãƒ—ãƒ­ãƒƒãƒˆ\n\n\nãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹\nPandas\nãƒ‡ãƒ¼ã‚¿å‡¦ç†ã€ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°\n\n\nãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†\nGit\nå…¨ã‚³ãƒ¼ãƒ‰ã®å±¥æ­´ç®¡ç†ã¨ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"
  },
  {
    "objectID": "about.html#é€£çµ¡å…ˆ",
    "href": "about.html#é€£çµ¡å…ˆ",
    "title": "Tako ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã¤ã„ã¦",
    "section": "",
    "text": "æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚„åˆ†æå†…å®¹ã«é–¢ã™ã‚‹ã”è³ªå•ã€ã”ææ¡ˆãªã©ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã€ä»¥ä¸‹ã¾ã§ãŠæ°—è»½ã«ã”é€£çµ¡ãã ã•ã„ã€‚\n\nE-mail: contact@tako-data.jp (ä»®æƒ³)\nãƒªãƒã‚¸ãƒˆãƒª: [GitHubã¸ã®ãƒªãƒ³ã‚¯] (ã“ã®ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã¯ã“ã¡ã‚‰)\n\n\n\nã€ŒTakoã€ã¯ã€è§¦æ‰‹ã®ã‚ˆã†ã«å¤šè§’çš„ãªè¦–ç‚¹ã§ãƒ‡ãƒ¼ã‚¿ã«ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã—ã€çŸ¥è­˜ã‚’çµ„ç¹”åŒ–ï¼ˆOrganizationï¼‰ã™ã‚‹ã“ã¨ã‚’è±¡å¾´ã—ã¦ã„ã¾ã™ã€‚"
  },
  {
    "objectID": "demo/basic_baysian_models/beisyan_modeling.html",
    "href": "demo/basic_baysian_models/beisyan_modeling.html",
    "title": "Understanding the Basics of Markdown",
    "section": "",
    "text": "å‚ç…§ã•ã›ã¦ã„ãŸã ã„ãŸè¨˜äº‹: ã€ãƒ™ã‚¤ã‚ºçµ±è¨ˆãƒ¢ãƒ‡ãƒªãƒ³ã‚°å…¥é–€ã€‘NumPyroã§å›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’ã¤ãã‚‹\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport jax.numpy as jnp\nfrom jax import random, vmap, grad, jit, lax\n\nimport numpyro\nfrom numpyro import plate, sample\nfrom numpyro.infer import MCMC, NUTS, Predictive\nimport numpyro.distributions as dist\n\n\n\n\nCode\n# ãƒãƒƒãƒ—ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\ndf = sns.load_dataset(\"tips\")\n\n# ä¼šè¨ˆç·é¡ã¨ãƒãƒƒãƒ—ã®ãƒ‡ãƒ¼ã‚¿ã‚’å¯è¦–åŒ–\nsns.set(style=\"darkgrid\")\nsns.jointplot(\n    x=\"total_bill\",\n    y=\"tip\",\n    data=df,\n    kind=\"scatter\",\n    xlim=(0, 60),\n    ylim=(0, 12),\n    color=\"b\",\n    height=7,\n)\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf.head()\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n\n\n\n\n\n\n\n\n\n\n\n\nimage.png\n\n\n\n\nCode\n# ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã®è¨­è¨ˆ\ndef model(X, Y=None):\n    pm_a = numpyro.sample(\"pm_a\", dist.Normal(0, 10))\n    pm_b = numpyro.sample(\"pm_b\", dist.Normal(0, 10))\n\n    mu = pm_a * X + pm_b\n    sigma = 1.0\n\n    pm_Y = numpyro.sample(\"pm_Y\", dist.Normal(mu, sigma), obs=Y)\n\n    return pm_Y\n\n\n\n\n\n\nCode\n# dfã‹ã‚‰numpy.ndarrayã«å¤‰æ›\nY = df[\"tip\"].values  # ç›®çš„å¤‰æ•°ï¼šY = [y0, y1, y2, ... yi]\nX = df[\"total_bill\"].values  # èª¬æ˜å¤‰æ•°ï¼šX = [x0, x1, x2, ... xi]\n\n\n\n\nCode\n# RUN MCMC\n# NUTS (No-U-Turn Sampler) is an adaptive variant of the Hamiltonian Monte Carlo (HMC) algorithm\n# HMCã®ã‚¹ãƒ†ãƒƒãƒ—ã‚µã‚¤ã‚ºã‚„åå¾©å›æ•°ãªã©ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è‡ªå‹•èª¿æ•´\n# åŠ¹ç‡çš„ãªã‚µãƒ³ãƒ—ãƒ«\n# åæŸã®æ”¹å–„\n# https://qiita.com/dai08srhg/items/5d4ac3070bae836aef10\nkernel = NUTS(model)\nmcmc = MCMC(kernel, num_warmup=1000, num_samples=2000)\nmcmc.run(rng_key=random.PRNGKey(0), X=X, Y=Y)\n\n# print MCMC summaryï¼ˆæ¨å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åŸºæœ¬çµ±è¨ˆé‡ï¼‰\nmcmc.print_summary()\n\n\nsample: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3000/3000 [00:00&lt;00:00, 3616.90it/s, 11 steps of size 2.54e-01. acc. prob=0.94]\n\n\n\n                mean       std    median      5.0%     95.0%     n_eff     r_hat\n      pm_a      0.11      0.01      0.11      0.09      0.12    368.76      1.00\n      pm_b      0.90      0.16      0.90      0.65      1.17    377.02      1.00\n\nNumber of divergences: 0\n\n\n\n\n\n\n\nCode\n# get param (num_samples=2000)\nmcmc_samples = mcmc.get_samples()\npm_a = mcmc_samples[\"pm_a\"]\npm_b = mcmc_samples[\"pm_b\"]\n\nprint(\"mcmc_samples:\", mcmc_samples)\nprint(\"pm_a:\", pm_a)\nprint(\"pm_b:\", pm_b)\n\n\nmcmc_samples: {'pm_a': Array([0.10649762, 0.110033  , 0.10530762, ..., 0.11129791, 0.10644959,\n       0.10579225], dtype=float32), 'pm_b': Array([0.86267745, 0.9398046 , 0.9131396 , ..., 0.751051  , 0.8998211 ,\n       0.8538504 ], dtype=float32)}\npm_a: [0.10649762 0.110033   0.10530762 ... 0.11129791 0.10644959 0.10579225]\npm_b: [0.86267745 0.9398046  0.9131396  ... 0.751051   0.8998211  0.8538504 ]\n\n\n\n\nCode\nlen(set(pm_a.tolist()))\n\n\n1971\n\n\n\n\nCode\n# å¯è¦–åŒ–\nsns.set(style=\"darkgrid\")\nplt.figure(figsize=(15, 5))\nplt.subplot(1, 2, 1)\nsns.distplot(pm_a)\nplt.title(\"Probability Density of pm_a\")\n\nplt.subplot(1, 2, 2)\nsns.distplot(pm_b)\nplt.title(\"Probability Density of pm_b\")\nplt.show()\n\n\nC:\\Users\\takuk\\AppData\\Local\\Temp\\ipykernel_27764\\3318693772.py:5: UserWarning: \n\n`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n\nPlease adapt your code to use either `displot` (a figure-level function with\nsimilar flexibility) or `histplot` (an axes-level function for histograms).\n\nFor a guide to updating your code to use the new functions, please see\nhttps://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n\n  sns.distplot(pm_a)\nC:\\Users\\takuk\\AppData\\Local\\Temp\\ipykernel_27764\\3318693772.py:9: UserWarning: \n\n`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n\nPlease adapt your code to use either `displot` (a figure-level function with\nsimilar flexibility) or `histplot` (an axes-level function for histograms).\n\nFor a guide to updating your code to use the new functions, please see\nhttps://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n\n  sns.distplot(pm_b)\n\n\n\n\n\n\n\n\n\n\n\nCode\nX_range = jnp.linspace(0, 50, 51)\n\npredictive = Predictive(model, mcmc_samples)\npredict_samples = predictive(random.PRNGKey(1), X=X_range, Y=None)\nprint(predict_samples)\n\n\n{'pm_Y': Array([[ 1.810429  ,  0.02438818,  0.22200845, ...,  5.2724934 ,\n         6.715812  ,  6.422859  ],\n       [ 0.15076251,  0.8095171 ,  0.21540537, ...,  5.2437186 ,\n         7.817451  ,  6.173345  ],\n       [ 2.476837  ,  0.21040367,  0.42815638, ...,  8.04783   ,\n         7.40407   ,  5.8891115 ],\n       ...,\n       [ 1.0230944 ,  1.1552314 ,  0.25326768, ...,  4.831621  ,\n         7.0255423 ,  5.759563  ],\n       [ 1.5060548 , -0.62601656,  1.4508446 , ...,  5.9778643 ,\n         6.058488  ,  4.774219  ],\n       [ 1.0496006 ,  0.51519567,  1.4674567 , ...,  5.349556  ,\n         4.992259  ,  6.651703  ]], dtype=float32)}\n\n\n\n\nCode\npm_Y = predict_samples[\"pm_Y\"]\nprint(pm_Y)\n\n\n[[ 1.810429    0.02438818  0.22200845 ...  5.2724934   6.715812\n   6.422859  ]\n [ 0.15076251  0.8095171   0.21540537 ...  5.2437186   7.817451\n   6.173345  ]\n [ 2.476837    0.21040367  0.42815638 ...  8.04783     7.40407\n   5.8891115 ]\n ...\n [ 1.0230944   1.1552314   0.25326768 ...  4.831621    7.0255423\n   5.759563  ]\n [ 1.5060548  -0.62601656  1.4508446  ...  5.9778643   6.058488\n   4.774219  ]\n [ 1.0496006   0.51519567  1.4674567  ...  5.349556    4.992259\n   6.651703  ]]\n\n\n\n\nCode\nlen(pm_Y)\n\n\n2000\n\n\n\n\n\n\n\nCode\nmean_Y = pm_Y.mean(axis=0)\ny_low, y_high = jnp.percentile(pm_Y, jnp.array([2.5, 97.5]), axis=0)\n\n# å¯è¦–åŒ–\nfig = plt.figure(figsize=(6.0, 6.0))\nplt.plot(X_range, mean_Y, \"-\", color=\"g\")\nplt.fill_between(X_range, y_low, y_high, color=\"g\", alpha=0.3)\nplt.plot(X, Y, \"o\")\nplt.xlabel(\"x\"), plt.ylabel(\"y\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nN = len(pm_a)\n# X_range = jnp.linspace(0, 50, 50)\n\n# äºˆæ¸¬çµæœã®å¯è¦–åŒ–\nfig = plt.figure(figsize=(6.0, 6.0))\nfor i in range(N):\n    pm_y = [pm_a[i] * x + pm_b[i] for x in X_range]\n    plt.plot(X_range, pm_y, \"g-\", alpha=0.5)\n\n# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å¯è¦–åŒ–\nplt.plot(X, Y, \"o\")\nplt.xlabel(\"x\"), plt.ylabel(\"y\")\nplt.title(\"linear regression\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\ndef my_model(mcmc_samples, X):\n    \"\"\"ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«\"\"\"\n    mcmc_samples = mcmc.get_samples()\n    pm_a = mcmc_samples[\"pm_a\"]\n    pm_b = mcmc_samples[\"pm_b\"]\n\n    # å¹³å‡å€¤\n    mu_a = jnp.mean(pm_a, axis=0)\n    mu_b = jnp.mean(pm_b, axis=0)\n    print(\"mu_a=\", mu_a)\n    print(\"mu_b=\", mu_b)\n\n    # ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«\n    Y_hat = mu_a * X + mu_b\n\n    return Y_hat\n\n\n\n\nCode\n# äºˆæ¸¬å€¤\nY_hat = my_model(mcmc_samples, X)\n\n# å¯è¦–åŒ–\nfig = plt.figure(figsize=(6.0, 6.0))\nplt.plot(X, Y, \"o\")\nplt.plot(X, Y_hat, \"g-\")\nplt.xlabel(\"x\"), plt.ylabel(\"y\")\nplt.title(\"linear regression\")\nplt.show()\n\n\nmu_a= 0.10581156\nmu_b= 0.9027909\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimage.png\n\n\n\n\nCode\n# ãƒã‚¢ã‚½ãƒ³å›å¸°ãƒ¢ãƒ‡ãƒ«ã®è¨­è¨ˆ\ndef model(X, Y=None):\n    pm_a = numpyro.sample(\"pm_a\", dist.Normal(0.0, 10.0))\n    pm_b = numpyro.sample(\"pm_b\", dist.Normal(0.0, 10.0))\n\n    theta = pm_a * X + pm_b\n    mu = jnp.exp(theta)\n\n    numpyro.sample(\"pm_Y\", dist.Poisson(mu), obs=Y)\n\n\n\n\nCode\n# Run MCMC\nkernel = NUTS(model)\n# mcmc = MCMC(kernel, num_warmup=1000, num_samples=2000, num_chains=4)\nmcmc = MCMC(kernel, num_warmup=1000, num_samples=2000)\nmcmc.run(rng_key=random.PRNGKey(0), X=X, Y=Y)\n\n# print MCMC summaryï¼ˆäº‹å¾Œåˆ†å¸ƒã®åŸºæœ¬çµ±è¨ˆé‡ã‚’ç¢ºèªï¼‰\nmcmc.print_summary()\n\n\nsample: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3000/3000 [00:00&lt;00:00, 3858.36it/s, 15 steps of size 2.37e-01. acc. prob=0.94]\n\n\n\n                mean       std    median      5.0%     95.0%     n_eff     r_hat\n      pm_a      0.03      0.00      0.03      0.02      0.04    435.78      1.00\n      pm_b      0.46      0.09      0.45      0.31      0.59    399.54      1.00\n\nNumber of divergences: 0\n\n\n\n\n\n\n\nCode\n# get param (num_samples=2000)\nmcmc_samples = mcmc.get_samples()\npm_a = mcmc_samples[\"pm_a\"]\npm_b = mcmc_samples[\"pm_b\"]\n\nprint(\"mcmc_samples:\", mcmc_samples)\nprint(\"pm_a:\", pm_a)\nprint(\"pm_b:\", pm_b)\n\n\nmcmc_samples: {'pm_a': Array([0.03003247, 0.0300827 , 0.02773185, ..., 0.03265581, 0.03095045,\n       0.03059688], dtype=float32), 'pm_b': Array([0.5058282 , 0.5151023 , 0.5058284 , ..., 0.37341517, 0.4465436 ,\n       0.42378387], dtype=float32)}\npm_a: [0.03003247 0.0300827  0.02773185 ... 0.03265581 0.03095045 0.03059688]\npm_b: [0.5058282  0.5151023  0.5058284  ... 0.37341517 0.4465436  0.42378387]\n\n\n\n\nCode\n# å¯è¦–åŒ–\nsns.set(style=\"darkgrid\")\nplt.figure(figsize=(15, 5))\nplt.subplot(1, 2, 1)\nsns.distplot(pm_a)\nplt.title(\"Probability Density of pm_a\")\n\nplt.subplot(1, 2, 2)\nsns.distplot(pm_b)\nplt.title(\"Probability Density of pm_b\")\nplt.show()\n\n\nC:\\Users\\takuk\\AppData\\Local\\Temp\\ipykernel_27764\\3318693772.py:5: UserWarning: \n\n`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n\nPlease adapt your code to use either `displot` (a figure-level function with\nsimilar flexibility) or `histplot` (an axes-level function for histograms).\n\nFor a guide to updating your code to use the new functions, please see\nhttps://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n\n  sns.distplot(pm_a)\nC:\\Users\\takuk\\AppData\\Local\\Temp\\ipykernel_27764\\3318693772.py:9: UserWarning: \n\n`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n\nPlease adapt your code to use either `displot` (a figure-level function with\nsimilar flexibility) or `histplot` (an axes-level function for histograms).\n\nFor a guide to updating your code to use the new functions, please see\nhttps://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n\n  sns.distplot(pm_b)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nX_range = jnp.linspace(0, 50, 50)\n\npredictive = Predictive(model, mcmc_samples)\npredict_samples = predictive(random.PRNGKey(0), X=X_range, Y=None)\n# print(predict_samples)\n\npm_Y = predict_samples[\"pm_Y\"]\n# print(pm_Y)\n\nmean_Y = pm_Y.mean(axis=0)\ny_low, y_high = jnp.percentile(pm_Y, jnp.array([2.5, 97.5]), axis=0)\n\n# å¯è¦–åŒ–\nfig = plt.figure(figsize=(6.0, 6.0))\nplt.plot(X_range, mean_Y, \"-\", color=\"g\")\nplt.fill_between(X_range, y_low, y_high, color=\"g\", alpha=0.3)\nplt.plot(X, Y, \"o\")\nplt.xlabel(\"x\"), plt.ylabel(\"y\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nN = len(pm_a)\n# X_range = jnp.linspace(0, 50, 50)\n\n# äºˆæ¸¬çµæœã®å¯è¦–åŒ–\nfig = plt.figure(figsize=(6.0, 6.0))\nfor i in range(N):\n    pm_y = [jnp.exp(pm_a[i] * x + pm_b[i]) for x in X_range]\n    plt.plot(X_range, pm_y, \"g-\", alpha=0.5)\n\n# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å¯è¦–åŒ–\nplt.plot(X, Y, \"o\")\nplt.xlabel(\"x\"), plt.ylabel(\"y\")\nplt.title(\"linear regression\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\ndef my_model(mcmc_samples, X):\n    \"\"\"ãƒã‚¢ã‚½ãƒ³å›å¸°ãƒ¢ãƒ‡ãƒ«\"\"\"\n    mcmc_samples = mcmc.get_samples()\n    pm_a = mcmc_samples[\"pm_a\"]\n    pm_b = mcmc_samples[\"pm_b\"]\n\n    # å¹³å‡å€¤\n    mu_a = jnp.mean(pm_a, axis=0)\n    mu_b = jnp.mean(pm_b, axis=0)\n    print(\"mu_a=\", mu_a)\n    print(\"mu_b=\", mu_b)\n\n    # ãƒã‚¢ã‚½ãƒ³å›å¸°ãƒ¢ãƒ‡ãƒ«\n    Y_hat = jnp.exp(mu_a * X + mu_b)\n\n    return Y_hat\n\n\n# äºˆæ¸¬å€¤\nY_hat = my_model(mcmc_samples, X_range)\n\n# å¯è¦–åŒ–\nfig = plt.figure(figsize=(6.0, 6.0))\nplt.plot(X, Y, \"o\")\nplt.plot(X_range, Y_hat, \"g-\")\nplt.xlabel(\"x\"), plt.ylabel(\"y\")\nplt.title(\"poisson regression\")\nplt.show()\n\n\nmu_a= 0.030312581\nmu_b= 0.45623016"
  },
  {
    "objectID": "demo/basic_baysian_models/beisyan_modeling.html#ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«-",
    "href": "demo/basic_baysian_models/beisyan_modeling.html#ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«-",
    "title": "Understanding the Basics of Markdown",
    "section": "",
    "text": "image.png\n\n\n\n\nCode\n# ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã®è¨­è¨ˆ\ndef model(X, Y=None):\n    pm_a = numpyro.sample(\"pm_a\", dist.Normal(0, 10))\n    pm_b = numpyro.sample(\"pm_b\", dist.Normal(0, 10))\n\n    mu = pm_a * X + pm_b\n    sigma = 1.0\n\n    pm_Y = numpyro.sample(\"pm_Y\", dist.Normal(mu, sigma), obs=Y)\n\n    return pm_Y\n\n\n\n\n\n\nCode\n# dfã‹ã‚‰numpy.ndarrayã«å¤‰æ›\nY = df[\"tip\"].values  # ç›®çš„å¤‰æ•°ï¼šY = [y0, y1, y2, ... yi]\nX = df[\"total_bill\"].values  # èª¬æ˜å¤‰æ•°ï¼šX = [x0, x1, x2, ... xi]\n\n\n\n\nCode\n# RUN MCMC\n# NUTS (No-U-Turn Sampler) is an adaptive variant of the Hamiltonian Monte Carlo (HMC) algorithm\n# HMCã®ã‚¹ãƒ†ãƒƒãƒ—ã‚µã‚¤ã‚ºã‚„åå¾©å›æ•°ãªã©ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è‡ªå‹•èª¿æ•´\n# åŠ¹ç‡çš„ãªã‚µãƒ³ãƒ—ãƒ«\n# åæŸã®æ”¹å–„\n# https://qiita.com/dai08srhg/items/5d4ac3070bae836aef10\nkernel = NUTS(model)\nmcmc = MCMC(kernel, num_warmup=1000, num_samples=2000)\nmcmc.run(rng_key=random.PRNGKey(0), X=X, Y=Y)\n\n# print MCMC summaryï¼ˆæ¨å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åŸºæœ¬çµ±è¨ˆé‡ï¼‰\nmcmc.print_summary()\n\n\nsample: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3000/3000 [00:00&lt;00:00, 3616.90it/s, 11 steps of size 2.54e-01. acc. prob=0.94]\n\n\n\n                mean       std    median      5.0%     95.0%     n_eff     r_hat\n      pm_a      0.11      0.01      0.11      0.09      0.12    368.76      1.00\n      pm_b      0.90      0.16      0.90      0.65      1.17    377.02      1.00\n\nNumber of divergences: 0\n\n\n\n\n\n\n\nCode\n# get param (num_samples=2000)\nmcmc_samples = mcmc.get_samples()\npm_a = mcmc_samples[\"pm_a\"]\npm_b = mcmc_samples[\"pm_b\"]\n\nprint(\"mcmc_samples:\", mcmc_samples)\nprint(\"pm_a:\", pm_a)\nprint(\"pm_b:\", pm_b)\n\n\nmcmc_samples: {'pm_a': Array([0.10649762, 0.110033  , 0.10530762, ..., 0.11129791, 0.10644959,\n       0.10579225], dtype=float32), 'pm_b': Array([0.86267745, 0.9398046 , 0.9131396 , ..., 0.751051  , 0.8998211 ,\n       0.8538504 ], dtype=float32)}\npm_a: [0.10649762 0.110033   0.10530762 ... 0.11129791 0.10644959 0.10579225]\npm_b: [0.86267745 0.9398046  0.9131396  ... 0.751051   0.8998211  0.8538504 ]\n\n\n\n\nCode\nlen(set(pm_a.tolist()))\n\n\n1971\n\n\n\n\nCode\n# å¯è¦–åŒ–\nsns.set(style=\"darkgrid\")\nplt.figure(figsize=(15, 5))\nplt.subplot(1, 2, 1)\nsns.distplot(pm_a)\nplt.title(\"Probability Density of pm_a\")\n\nplt.subplot(1, 2, 2)\nsns.distplot(pm_b)\nplt.title(\"Probability Density of pm_b\")\nplt.show()\n\n\nC:\\Users\\takuk\\AppData\\Local\\Temp\\ipykernel_27764\\3318693772.py:5: UserWarning: \n\n`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n\nPlease adapt your code to use either `displot` (a figure-level function with\nsimilar flexibility) or `histplot` (an axes-level function for histograms).\n\nFor a guide to updating your code to use the new functions, please see\nhttps://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n\n  sns.distplot(pm_a)\nC:\\Users\\takuk\\AppData\\Local\\Temp\\ipykernel_27764\\3318693772.py:9: UserWarning: \n\n`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n\nPlease adapt your code to use either `displot` (a figure-level function with\nsimilar flexibility) or `histplot` (an axes-level function for histograms).\n\nFor a guide to updating your code to use the new functions, please see\nhttps://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n\n  sns.distplot(pm_b)\n\n\n\n\n\n\n\n\n\n\n\nCode\nX_range = jnp.linspace(0, 50, 51)\n\npredictive = Predictive(model, mcmc_samples)\npredict_samples = predictive(random.PRNGKey(1), X=X_range, Y=None)\nprint(predict_samples)\n\n\n{'pm_Y': Array([[ 1.810429  ,  0.02438818,  0.22200845, ...,  5.2724934 ,\n         6.715812  ,  6.422859  ],\n       [ 0.15076251,  0.8095171 ,  0.21540537, ...,  5.2437186 ,\n         7.817451  ,  6.173345  ],\n       [ 2.476837  ,  0.21040367,  0.42815638, ...,  8.04783   ,\n         7.40407   ,  5.8891115 ],\n       ...,\n       [ 1.0230944 ,  1.1552314 ,  0.25326768, ...,  4.831621  ,\n         7.0255423 ,  5.759563  ],\n       [ 1.5060548 , -0.62601656,  1.4508446 , ...,  5.9778643 ,\n         6.058488  ,  4.774219  ],\n       [ 1.0496006 ,  0.51519567,  1.4674567 , ...,  5.349556  ,\n         4.992259  ,  6.651703  ]], dtype=float32)}\n\n\n\n\nCode\npm_Y = predict_samples[\"pm_Y\"]\nprint(pm_Y)\n\n\n[[ 1.810429    0.02438818  0.22200845 ...  5.2724934   6.715812\n   6.422859  ]\n [ 0.15076251  0.8095171   0.21540537 ...  5.2437186   7.817451\n   6.173345  ]\n [ 2.476837    0.21040367  0.42815638 ...  8.04783     7.40407\n   5.8891115 ]\n ...\n [ 1.0230944   1.1552314   0.25326768 ...  4.831621    7.0255423\n   5.759563  ]\n [ 1.5060548  -0.62601656  1.4508446  ...  5.9778643   6.058488\n   4.774219  ]\n [ 1.0496006   0.51519567  1.4674567  ...  5.349556    4.992259\n   6.651703  ]]\n\n\n\n\nCode\nlen(pm_Y)\n\n\n2000\n\n\n\n\n\n\n\nCode\nmean_Y = pm_Y.mean(axis=0)\ny_low, y_high = jnp.percentile(pm_Y, jnp.array([2.5, 97.5]), axis=0)\n\n# å¯è¦–åŒ–\nfig = plt.figure(figsize=(6.0, 6.0))\nplt.plot(X_range, mean_Y, \"-\", color=\"g\")\nplt.fill_between(X_range, y_low, y_high, color=\"g\", alpha=0.3)\nplt.plot(X, Y, \"o\")\nplt.xlabel(\"x\"), plt.ylabel(\"y\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nN = len(pm_a)\n# X_range = jnp.linspace(0, 50, 50)\n\n# äºˆæ¸¬çµæœã®å¯è¦–åŒ–\nfig = plt.figure(figsize=(6.0, 6.0))\nfor i in range(N):\n    pm_y = [pm_a[i] * x + pm_b[i] for x in X_range]\n    plt.plot(X_range, pm_y, \"g-\", alpha=0.5)\n\n# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å¯è¦–åŒ–\nplt.plot(X, Y, \"o\")\nplt.xlabel(\"x\"), plt.ylabel(\"y\")\nplt.title(\"linear regression\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\ndef my_model(mcmc_samples, X):\n    \"\"\"ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«\"\"\"\n    mcmc_samples = mcmc.get_samples()\n    pm_a = mcmc_samples[\"pm_a\"]\n    pm_b = mcmc_samples[\"pm_b\"]\n\n    # å¹³å‡å€¤\n    mu_a = jnp.mean(pm_a, axis=0)\n    mu_b = jnp.mean(pm_b, axis=0)\n    print(\"mu_a=\", mu_a)\n    print(\"mu_b=\", mu_b)\n\n    # ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«\n    Y_hat = mu_a * X + mu_b\n\n    return Y_hat\n\n\n\n\nCode\n# äºˆæ¸¬å€¤\nY_hat = my_model(mcmc_samples, X)\n\n# å¯è¦–åŒ–\nfig = plt.figure(figsize=(6.0, 6.0))\nplt.plot(X, Y, \"o\")\nplt.plot(X, Y_hat, \"g-\")\nplt.xlabel(\"x\"), plt.ylabel(\"y\")\nplt.title(\"linear regression\")\nplt.show()\n\n\nmu_a= 0.10581156\nmu_b= 0.9027909"
  },
  {
    "objectID": "demo/basic_baysian_models/beisyan_modeling.html#ãƒã‚¢ã‚½ãƒ³å›å¸°ãƒ¢ãƒ‡ãƒ«",
    "href": "demo/basic_baysian_models/beisyan_modeling.html#ãƒã‚¢ã‚½ãƒ³å›å¸°ãƒ¢ãƒ‡ãƒ«",
    "title": "Understanding the Basics of Markdown",
    "section": "",
    "text": "image.png\n\n\n\n\nCode\n# ãƒã‚¢ã‚½ãƒ³å›å¸°ãƒ¢ãƒ‡ãƒ«ã®è¨­è¨ˆ\ndef model(X, Y=None):\n    pm_a = numpyro.sample(\"pm_a\", dist.Normal(0.0, 10.0))\n    pm_b = numpyro.sample(\"pm_b\", dist.Normal(0.0, 10.0))\n\n    theta = pm_a * X + pm_b\n    mu = jnp.exp(theta)\n\n    numpyro.sample(\"pm_Y\", dist.Poisson(mu), obs=Y)\n\n\n\n\nCode\n# Run MCMC\nkernel = NUTS(model)\n# mcmc = MCMC(kernel, num_warmup=1000, num_samples=2000, num_chains=4)\nmcmc = MCMC(kernel, num_warmup=1000, num_samples=2000)\nmcmc.run(rng_key=random.PRNGKey(0), X=X, Y=Y)\n\n# print MCMC summaryï¼ˆäº‹å¾Œåˆ†å¸ƒã®åŸºæœ¬çµ±è¨ˆé‡ã‚’ç¢ºèªï¼‰\nmcmc.print_summary()\n\n\nsample: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3000/3000 [00:00&lt;00:00, 3858.36it/s, 15 steps of size 2.37e-01. acc. prob=0.94]\n\n\n\n                mean       std    median      5.0%     95.0%     n_eff     r_hat\n      pm_a      0.03      0.00      0.03      0.02      0.04    435.78      1.00\n      pm_b      0.46      0.09      0.45      0.31      0.59    399.54      1.00\n\nNumber of divergences: 0\n\n\n\n\n\n\n\nCode\n# get param (num_samples=2000)\nmcmc_samples = mcmc.get_samples()\npm_a = mcmc_samples[\"pm_a\"]\npm_b = mcmc_samples[\"pm_b\"]\n\nprint(\"mcmc_samples:\", mcmc_samples)\nprint(\"pm_a:\", pm_a)\nprint(\"pm_b:\", pm_b)\n\n\nmcmc_samples: {'pm_a': Array([0.03003247, 0.0300827 , 0.02773185, ..., 0.03265581, 0.03095045,\n       0.03059688], dtype=float32), 'pm_b': Array([0.5058282 , 0.5151023 , 0.5058284 , ..., 0.37341517, 0.4465436 ,\n       0.42378387], dtype=float32)}\npm_a: [0.03003247 0.0300827  0.02773185 ... 0.03265581 0.03095045 0.03059688]\npm_b: [0.5058282  0.5151023  0.5058284  ... 0.37341517 0.4465436  0.42378387]\n\n\n\n\nCode\n# å¯è¦–åŒ–\nsns.set(style=\"darkgrid\")\nplt.figure(figsize=(15, 5))\nplt.subplot(1, 2, 1)\nsns.distplot(pm_a)\nplt.title(\"Probability Density of pm_a\")\n\nplt.subplot(1, 2, 2)\nsns.distplot(pm_b)\nplt.title(\"Probability Density of pm_b\")\nplt.show()\n\n\nC:\\Users\\takuk\\AppData\\Local\\Temp\\ipykernel_27764\\3318693772.py:5: UserWarning: \n\n`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n\nPlease adapt your code to use either `displot` (a figure-level function with\nsimilar flexibility) or `histplot` (an axes-level function for histograms).\n\nFor a guide to updating your code to use the new functions, please see\nhttps://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n\n  sns.distplot(pm_a)\nC:\\Users\\takuk\\AppData\\Local\\Temp\\ipykernel_27764\\3318693772.py:9: UserWarning: \n\n`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n\nPlease adapt your code to use either `displot` (a figure-level function with\nsimilar flexibility) or `histplot` (an axes-level function for histograms).\n\nFor a guide to updating your code to use the new functions, please see\nhttps://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n\n  sns.distplot(pm_b)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nX_range = jnp.linspace(0, 50, 50)\n\npredictive = Predictive(model, mcmc_samples)\npredict_samples = predictive(random.PRNGKey(0), X=X_range, Y=None)\n# print(predict_samples)\n\npm_Y = predict_samples[\"pm_Y\"]\n# print(pm_Y)\n\nmean_Y = pm_Y.mean(axis=0)\ny_low, y_high = jnp.percentile(pm_Y, jnp.array([2.5, 97.5]), axis=0)\n\n# å¯è¦–åŒ–\nfig = plt.figure(figsize=(6.0, 6.0))\nplt.plot(X_range, mean_Y, \"-\", color=\"g\")\nplt.fill_between(X_range, y_low, y_high, color=\"g\", alpha=0.3)\nplt.plot(X, Y, \"o\")\nplt.xlabel(\"x\"), plt.ylabel(\"y\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nN = len(pm_a)\n# X_range = jnp.linspace(0, 50, 50)\n\n# äºˆæ¸¬çµæœã®å¯è¦–åŒ–\nfig = plt.figure(figsize=(6.0, 6.0))\nfor i in range(N):\n    pm_y = [jnp.exp(pm_a[i] * x + pm_b[i]) for x in X_range]\n    plt.plot(X_range, pm_y, \"g-\", alpha=0.5)\n\n# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å¯è¦–åŒ–\nplt.plot(X, Y, \"o\")\nplt.xlabel(\"x\"), plt.ylabel(\"y\")\nplt.title(\"linear regression\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\ndef my_model(mcmc_samples, X):\n    \"\"\"ãƒã‚¢ã‚½ãƒ³å›å¸°ãƒ¢ãƒ‡ãƒ«\"\"\"\n    mcmc_samples = mcmc.get_samples()\n    pm_a = mcmc_samples[\"pm_a\"]\n    pm_b = mcmc_samples[\"pm_b\"]\n\n    # å¹³å‡å€¤\n    mu_a = jnp.mean(pm_a, axis=0)\n    mu_b = jnp.mean(pm_b, axis=0)\n    print(\"mu_a=\", mu_a)\n    print(\"mu_b=\", mu_b)\n\n    # ãƒã‚¢ã‚½ãƒ³å›å¸°ãƒ¢ãƒ‡ãƒ«\n    Y_hat = jnp.exp(mu_a * X + mu_b)\n\n    return Y_hat\n\n\n# äºˆæ¸¬å€¤\nY_hat = my_model(mcmc_samples, X_range)\n\n# å¯è¦–åŒ–\nfig = plt.figure(figsize=(6.0, 6.0))\nplt.plot(X, Y, \"o\")\nplt.plot(X_range, Y_hat, \"g-\")\nplt.xlabel(\"x\"), plt.ylabel(\"y\")\nplt.title(\"poisson regression\")\nplt.show()\n\n\nmu_a= 0.030312581\nmu_b= 0.45623016"
  },
  {
    "objectID": "demo/basic_time_series_models/sarima_demo.html",
    "href": "demo/basic_time_series_models/sarima_demo.html",
    "title": "SARIMAã‚’ä½¿ã£ãŸåŒ»ç™‚è²»äºˆæ¸¬ã®ãƒ‡ãƒ¢",
    "section": "",
    "text": "SARIMAï¼ˆSeasonal AutoRegressive Integrated Moving Averageï¼‰ã¯ã€å­£ç¯€æ€§ã®ã‚ã‚‹æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã«é©ã—ãŸäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚\nåŒ»ç™‚è²»ã®éšå·®ã‚’å–ã‚‹ã¨ã€å®šå¸¸åˆ†å¸ƒã«è¿‘ã¥ãã€åŒ»ç™‚è²»ã¯å†¬ã¯ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚¶ãŒæµè¡Œã£ãŸã‚Šå¤ã¯ç†±ä¸­ç—‡ãŒå¢—ãˆãŸã‚Šã¨å­£ç¯€æ€§ãŒã‚ã‚‹ãŸã‚ã€SARIMAãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦åŒ»ç™‚è²»ã®äºˆæ¸¬ã‚’è¡Œã„ã¾ã™ã€‚\nimport numpy as np\nimport pandas as pd\nimport plotly.graph_objects as go\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nimport warnings\n\n# è­¦å‘Šã‚’ç„¡è¦–ï¼ˆåæŸã«é–¢ã™ã‚‹è­¦å‘Šãªã©ãŒå‡ºã‚‹å ´åˆãŒã‚ã‚‹ãŸã‚ï¼‰\nwarnings.filterwarnings(\"ignore\")"
  },
  {
    "objectID": "demo/basic_time_series_models/sarima_demo.html#ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™",
    "href": "demo/basic_time_series_models/sarima_demo.html#ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™",
    "title": "SARIMAã‚’ä½¿ã£ãŸåŒ»ç™‚è²»äºˆæ¸¬ã®ãƒ‡ãƒ¢",
    "section": "1. ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™",
    "text": "1. ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™\n\n# 1. ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ\nnp.random.seed(42)\n\n# æœŸé–“: éå»10å¹´åˆ† (120ãƒ¶æœˆ)\ndates = pd.date_range(start='2015-01-01', periods=120, freq='MS')\n\n# ãƒˆãƒ¬ãƒ³ãƒ‰: å¾ã€…ã«åŒ»ç™‚è²»ãŒä¸ŠãŒã£ã¦ã„ã (ç·šå½¢ãƒˆãƒ¬ãƒ³ãƒ‰)\ntrend = np.linspace(100, 150, 120)  # 100å˜ä½ã‹ã‚‰1000å˜ä½ã¸ä¸Šæ˜‡ &lt;- ã“ã“ã‚’å¤‰ãˆãŸã€‚\n\n# å­£ç¯€æ€§: 12ãƒ¶æœˆå‘¨æœŸ (ä¾‹: å†¬ã«é«˜ãã€å¤ã«ä½ã„ãªã©)\nseasonality = 10 * np.sin(np.linspace(0, 20 * np.pi, 120))\n\n# ãƒã‚¤ã‚º: ãƒ©ãƒ³ãƒ€ãƒ ãªå¤‰å‹•\nnoise = np.random.normal(scale=3, size=120)\n\n# åˆæˆã—ã¦ã€Œæœˆæ¬¡åŒ»ç™‚è²»ãƒ‡ãƒ¼ã‚¿ã€ã¨ã™ã‚‹\nmedical_costs = trend + seasonality + noise\n\n# DataFrameåŒ–\ndf = pd.DataFrame({'Date': dates, 'Cost (100 million)': medical_costs})\ndf.set_index('Date', inplace=True)\ndf[\"Cost (100 million)\"]  = df[\"Cost (100 million)\"].round(2)\n\nprint(\"ãƒ‡ãƒ¼ã‚¿ã®å…ˆé ­5è¡Œ:\")\ndisplay(df.head())\n\nãƒ‡ãƒ¼ã‚¿ã®å…ˆé ­5è¡Œ:\n\n\n\n\n\n\n\n\n\nCost (100 million)\n\n\nDate\n\n\n\n\n\n2015-01-01\n101.49\n\n\n2015-02-01\n187.82\n\n\n2015-03-01\n277.03\n\n\n2015-04-01\n364.15\n\n\n2015-05-01\n440.64"
  },
  {
    "objectID": "demo/basic_time_series_models/sarima_demo.html#å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–-plotly",
    "href": "demo/basic_time_series_models/sarima_demo.html#å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–-plotly",
    "title": "SARIMAã‚’ä½¿ã£ãŸåŒ»ç™‚è²»äºˆæ¸¬ã®ãƒ‡ãƒ¢",
    "section": "å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ– (Plotly)",
    "text": "å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ– (Plotly)\n\n# 2. å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(\n    x=df.index,\n    y=df['Cost (100 million)'],\n    mode='lines+markers',\n    name='å®Ÿç¸¾å€¤',\n    line=dict(color='blue')\n))\n\nfig.update_layout(\n    title='åŒ»ç™‚è²»ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆéå»10å¹´ï¼‰',\n    xaxis_title='å¹´æœˆ',\n    yaxis_title='åŒ»ç™‚è²»ï¼ˆ1å„„å††ï¼‰',\n    template='plotly_white'\n)\n\nfig.show(renderer=\"notebook\")"
  },
  {
    "objectID": "demo/basic_time_series_models/sarima_demo.html#sarimaãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã¨å­¦ç¿’",
    "href": "demo/basic_time_series_models/sarima_demo.html#sarimaãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã¨å­¦ç¿’",
    "title": "SARIMAã‚’ä½¿ã£ãŸåŒ»ç™‚è²»äºˆæ¸¬ã®ãƒ‡ãƒ¢",
    "section": "SARIMAãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã¨å­¦ç¿’",
    "text": "SARIMAãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã¨å­¦ç¿’\n\\(\\phi_p(B) \\Phi_P(B^s) (1 - B)^d (1 - B^s)^D y_t = \\theta_q(B) \\Theta_Q(B^s) \\varepsilon_t\\)\nSARIMAãƒ¢ãƒ‡ãƒ«ï¼ˆå­£ç¯€æ€§è‡ªå·±å›å¸°å’Œåˆ†ç§»å‹•å¹³å‡ãƒ¢ãƒ‡ãƒ«ï¼‰ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚\nâ€»æœ¬æ¥ã¯AICãªã©ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢ã‚’è¡Œã„ã¾ã™ãŒã€ä»Šå›ã¯ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ã«åˆã‚ã›ã¦ä¸€èˆ¬çš„ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ \\((p, d, q) \\times (P, D, Q, s)\\) ã‚’è¨­å®šã—ã¾ã™ã€‚\n\n# 3. SARIMAãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰\n# order=(p, d, q), seasonal_order=(P, D, Q, s)\n# å‘¨æœŸ s=12 (æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿ã®ãŸã‚)\nsarima_model = SARIMAX(\n    df['Cost (100 million)'],\n    order=(1, 1, 1),\n    seasonal_order=(1, 1, 1, 12),\n    enforce_stationarity=False,\n    enforce_invertibility=False\n)\n\n# ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’\nsarima_result = sarima_model.fit()\n\nprint(sarima_result.summary())\n\n                                     SARIMAX Results                                      \n==========================================================================================\nDep. Variable:                 Cost (100 million)   No. Observations:                  120\nModel:             SARIMAX(1, 1, 1)x(1, 1, 1, 12)   Log Likelihood                -244.124\nDate:                            Sun, 14 Dec 2025   AIC                            498.249\nTime:                                    15:21:45   BIC                            510.912\nSample:                                01-01-2015   HQIC                           503.362\n                                     - 12-01-2024                                         \nCovariance Type:                              opg                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nar.L1          0.0269      0.121      0.223      0.824      -0.210       0.263\nma.L1         -1.0000    238.268     -0.004      0.997    -467.996     465.996\nar.S.L12      -0.2240      0.144     -1.554      0.120      -0.507       0.058\nma.S.L12      -0.5145      0.166     -3.101      0.002      -0.840      -0.189\nsigma2        10.2597   2444.753      0.004      0.997   -4781.367    4801.887\n===================================================================================\nLjung-Box (L1) (Q):                   0.01   Jarque-Bera (JB):                 0.43\nProb(Q):                              0.91   Prob(JB):                         0.81\nHeteroskedasticity (H):               0.95   Skew:                             0.08\nProb(H) (two-sided):                  0.88   Kurtosis:                         3.29\n===================================================================================\n\nWarnings:\n[1] Covariance matrix calculated using the outer product of gradients (complex-step)."
  },
  {
    "objectID": "demo/basic_time_series_models/sarima_demo.html#å‘ã“ã†5å¹´é–“ã®äºˆæ¸¬ã¨å¯è¦–åŒ–",
    "href": "demo/basic_time_series_models/sarima_demo.html#å‘ã“ã†5å¹´é–“ã®äºˆæ¸¬ã¨å¯è¦–åŒ–",
    "title": "SARIMAã‚’ä½¿ã£ãŸåŒ»ç™‚è²»äºˆæ¸¬ã®ãƒ‡ãƒ¢",
    "section": "å‘ã“ã†5å¹´é–“ã®äºˆæ¸¬ã¨å¯è¦–åŒ–",
    "text": "å‘ã“ã†5å¹´é–“ã®äºˆæ¸¬ã¨å¯è¦–åŒ–\n\n# 4. å‘ã“ã†5å¹´é–“ (60ãƒ¶æœˆ) ã®äºˆæ¸¬\nforecast_steps = 60\npred_uc = sarima_result.get_forecast(steps=forecast_steps)\n\n# äºˆæ¸¬å€¤ï¼ˆæœŸå¾…å€¤ï¼‰\npred_mean = pred_uc.predicted_mean\n\n# 95%ä¿¡é ¼åŒºé–“\npred_ci = pred_uc.conf_int()\n\n# --- å¯è¦–åŒ– ---\nfig_forecast = go.Figure()\n\n# 1. å®Ÿç¸¾å€¤ã®ãƒ—ãƒ­ãƒƒãƒˆ\nfig_forecast.add_trace(go.Scatter(\n    x=df.index,\n    y=df['Cost (100 million)'],\n    mode='lines',\n    name='å®Ÿç¸¾å€¤',\n    line=dict(color='blue')\n))\n\n# 2. äºˆæ¸¬å€¤ã®ãƒ—ãƒ­ãƒƒãƒˆ\nfig_forecast.add_trace(go.Scatter(\n    x=pred_mean.index,\n    y=pred_mean,\n    mode='lines',\n    name='äºˆæ¸¬å€¤ (ä»Šå¾Œ5å¹´)',\n    line=dict(color='red', dash='dash')\n))\n\n# 3. ä¿¡é ¼åŒºé–“ã®ãƒ—ãƒ­ãƒƒãƒˆ (ä¸Šé™ã¨ä¸‹é™ã®é–“ã‚’å¡—ã‚Šã¤ã¶ã™)\nfig_forecast.add_trace(go.Scatter(\n    x=pred_ci.index,\n    y=pred_ci.iloc[:, 0], # ä¸‹é™\n    mode='lines',\n    line=dict(width=0),\n    showlegend=False,\n    name='Lower Bound'\n))\n\nfig_forecast.add_trace(go.Scatter(\n    x=pred_ci.index,\n    y=pred_ci.iloc[:, 1], # ä¸Šé™\n    mode='lines',\n    line=dict(width=0),\n    fill='tonexty', # ã²ã¨ã¤å‰ã®ãƒˆãƒ¬ãƒ¼ã‚¹ï¼ˆä¸‹é™ï¼‰ã¨ã®é–“ã‚’åŸ‹ã‚ã‚‹\n    fillcolor='rgba(255, 0, 0, 0.2)', # èµ¤è‰²ã®åŠé€æ˜\n    name='95%ä¿¡é ¼åŒºé–“'\n))\n\nfig_forecast.update_layout(\n    title='SARIMAãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹åŒ»ç™‚è²»äºˆæ¸¬ï¼ˆå‘ã“ã†5å¹´ï¼‰',\n    xaxis_title='å¹´æœˆ',\n    yaxis_title='åŒ»ç™‚è²»',\n    template='plotly_white',\n    hovermode=\"x unified\"\n)\n\nfig_forecast.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json"
  },
  {
    "objectID": "demo/basic_time_series_models/sarima_demo.html#åŒ»ç™‚è²»ä¸Šæ˜‡é‡‘é¡ã®ç®—å‡º",
    "href": "demo/basic_time_series_models/sarima_demo.html#åŒ»ç™‚è²»ä¸Šæ˜‡é‡‘é¡ã®ç®—å‡º",
    "title": "SARIMAã‚’ä½¿ã£ãŸåŒ»ç™‚è²»äºˆæ¸¬ã®ãƒ‡ãƒ¢",
    "section": "åŒ»ç™‚è²»ä¸Šæ˜‡é‡‘é¡ã®ç®—å‡º",
    "text": "åŒ»ç™‚è²»ä¸Šæ˜‡é‡‘é¡ã®ç®—å‡º\n\n# 5. ä¸Šæ˜‡é‡‘é¡ã®ç®—å‡º\n\n# ç›´è¿‘1å¹´é–“ã®å®Ÿç¸¾åˆè¨ˆ\nlast_year_actual = df['Cost (100 million)'].iloc[-12:].sum()\n\n# 5å¹´å¾Œï¼ˆäºˆæ¸¬æœŸé–“ã®æœ€å¾Œã®1å¹´é–“ï¼‰ã®äºˆæ¸¬åˆè¨ˆ\nlast_year_forecast = pred_mean.iloc[-12:].sum()\n\n# ä¸Šæ˜‡é¡ã¨ä¸Šæ˜‡ç‡\nincrease_amount = last_year_forecast - last_year_actual\nincrease_rate = (increase_amount / last_year_actual) * 100\n\nprint(f\"--- åŒ»ç™‚è²»ä¸Šæ˜‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ---\")\nprint(f\"ç›´è¿‘1å¹´é–“ã®åŒ»ç™‚è²»åˆè¨ˆ: {last_year_actual:,.2f}\")\nprint(f\"5å¹´å¾Œã®å¹´é–“åŒ»ç™‚è²»åˆè¨ˆ: {last_year_forecast:,.2f}\")\nprint(f\"--------------------------------\")\nprint(f\"å¹´é–“å¢—åŠ é¡: +{increase_amount:,.2f}\")\nprint(f\"ä¸Šæ˜‡ç‡: {increase_rate:.2f}%\")\n\n--- åŒ»ç™‚è²»ä¸Šæ˜‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ---\nç›´è¿‘1å¹´é–“ã®åŒ»ç™‚è²»åˆè¨ˆ: 1,777.19\n5å¹´å¾Œã®å¹´é–“åŒ»ç™‚è²»åˆè¨ˆ: 2,088.13\n--------------------------------\nå¹´é–“å¢—åŠ é¡: +310.94\nä¸Šæ˜‡ç‡: 17.50%"
  },
  {
    "objectID": "demo/understanding_mercury/mine/sarima_demo.html",
    "href": "demo/understanding_mercury/mine/sarima_demo.html",
    "title": "SARIMAã‚’ä½¿ã£ãŸåŒ»ç™‚è²»äºˆæ¸¬ã®ãƒ‡ãƒ¢",
    "section": "",
    "text": "SARIMAï¼ˆSeasonal AutoRegressive Integrated Moving Averageï¼‰ã¯ã€å­£ç¯€æ€§ã®ã‚ã‚‹æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã«é©ã—ãŸäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚\nåŒ»ç™‚è²»ã®éšå·®ã‚’å–ã‚‹ã¨ã€å®šå¸¸åˆ†å¸ƒã«è¿‘ã¥ãã€åŒ»ç™‚è²»ã¯å†¬ã¯ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚¶ãŒæµè¡Œã£ãŸã‚Šå¤ã¯ç†±ä¸­ç—‡ãŒå¢—ãˆãŸã‚Šã¨å­£ç¯€æ€§ãŒã‚ã‚‹ãŸã‚ã€SARIMAãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦åŒ»ç™‚è²»ã®äºˆæ¸¬ã‚’è¡Œã„ã¾ã™ã€‚\nimport mercury as mr\napp = mr.App(title=\"demo analysis\") \n\nMercury ApplicationThis output won't appear in the web app.\nimport numpy as np\nimport pandas as pd\nimport plotly.graph_objects as go\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nimport warnings\n\n# è­¦å‘Šã‚’ç„¡è¦–ï¼ˆåæŸã«é–¢ã™ã‚‹è­¦å‘Šãªã©ãŒå‡ºã‚‹å ´åˆãŒã‚ã‚‹ãŸã‚ï¼‰\nwarnings.filterwarnings(\"ignore\")"
  },
  {
    "objectID": "demo/understanding_mercury/mine/sarima_demo.html#ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™",
    "href": "demo/understanding_mercury/mine/sarima_demo.html#ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™",
    "title": "SARIMAã‚’ä½¿ã£ãŸåŒ»ç™‚è²»äºˆæ¸¬ã®ãƒ‡ãƒ¢",
    "section": "1. ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™",
    "text": "1. ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™\n\n# 1. ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ\nnp.random.seed(42)\n\n# æœŸé–“: éå»10å¹´åˆ† (120ãƒ¶æœˆ)\ndates = pd.date_range(start='2015-01-01', periods=120, freq='MS')\n\n# ãƒˆãƒ¬ãƒ³ãƒ‰: å¾ã€…ã«åŒ»ç™‚è²»ãŒä¸ŠãŒã£ã¦ã„ã (ç·šå½¢ãƒˆãƒ¬ãƒ³ãƒ‰)\ntrend = np.linspace(100, 150, 120)  # 100å˜ä½ã‹ã‚‰1000å˜ä½ã¸ä¸Šæ˜‡ &lt;- ã“ã“ã‚’å¤‰ãˆãŸã€‚\n\n# å­£ç¯€æ€§: 12ãƒ¶æœˆå‘¨æœŸ (ä¾‹: å†¬ã«é«˜ãã€å¤ã«ä½ã„ãªã©)\nseasonality = 10 * np.sin(np.linspace(0, 20 * np.pi, 120))\n\n# ãƒã‚¤ã‚º: ãƒ©ãƒ³ãƒ€ãƒ ãªå¤‰å‹•\nnoise = np.random.normal(scale=3, size=120)\n\n# åˆæˆã—ã¦ã€Œæœˆæ¬¡åŒ»ç™‚è²»ãƒ‡ãƒ¼ã‚¿ã€ã¨ã™ã‚‹\nmedical_costs = trend + seasonality + noise\n\n# DataFrameåŒ–\ndf = pd.DataFrame({'Date': dates, 'Cost (100 million)': medical_costs})\ndf.set_index('Date', inplace=True)\ndf[\"Cost (100 million)\"]  = df[\"Cost (100 million)\"].round(2)\n\nprint(\"ãƒ‡ãƒ¼ã‚¿ã®å…ˆé ­5è¡Œ:\")\ndisplay(df.head())\n\nãƒ‡ãƒ¼ã‚¿ã®å…ˆé ­5è¡Œ:\n\n\n\n\n\n\n\n\n\nCost (100 million)\n\n\nDate\n\n\n\n\n\n2015-01-01\n101.49\n\n\n2015-02-01\n105.04\n\n\n2015-03-01\n111.49\n\n\n2015-04-01\n115.83\n\n\n2015-05-01\n109.55"
  },
  {
    "objectID": "demo/understanding_mercury/mine/sarima_demo.html#å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–-plotly",
    "href": "demo/understanding_mercury/mine/sarima_demo.html#å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–-plotly",
    "title": "SARIMAã‚’ä½¿ã£ãŸåŒ»ç™‚è²»äºˆæ¸¬ã®ãƒ‡ãƒ¢",
    "section": "å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ– (Plotly)",
    "text": "å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ– (Plotly)\n\n# 2. å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(\n    x=df.index,\n    y=df['Cost (100 million)'],\n    mode='lines+markers',\n    name='å®Ÿç¸¾å€¤',\n    line=dict(color='blue')\n))\n\nfig.update_layout(\n    title='åŒ»ç™‚è²»ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆéå»10å¹´ï¼‰',\n    xaxis_title='å¹´æœˆ',\n    yaxis_title='åŒ»ç™‚è²»ï¼ˆ1å„„å††ï¼‰',\n    template='plotly_white'\n)\n\nfig.show(renderer=\"notebook\")"
  },
  {
    "objectID": "demo/understanding_mercury/mine/sarima_demo.html#sarimaãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã¨å­¦ç¿’",
    "href": "demo/understanding_mercury/mine/sarima_demo.html#sarimaãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã¨å­¦ç¿’",
    "title": "SARIMAã‚’ä½¿ã£ãŸåŒ»ç™‚è²»äºˆæ¸¬ã®ãƒ‡ãƒ¢",
    "section": "SARIMAãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã¨å­¦ç¿’",
    "text": "SARIMAãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã¨å­¦ç¿’\n\\(\\phi_p(B) \\Phi_P(B^s) (1 - B)^d (1 - B^s)^D y_t = \\theta_q(B) \\Theta_Q(B^s) \\varepsilon_t\\)\nSARIMAãƒ¢ãƒ‡ãƒ«ï¼ˆå­£ç¯€æ€§è‡ªå·±å›å¸°å’Œåˆ†ç§»å‹•å¹³å‡ãƒ¢ãƒ‡ãƒ«ï¼‰ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚\nâ€»æœ¬æ¥ã¯AICãªã©ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢ã‚’è¡Œã„ã¾ã™ãŒã€ä»Šå›ã¯ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ã«åˆã‚ã›ã¦ä¸€èˆ¬çš„ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ \\((p, d, q) \\times (P, D, Q, s)\\) ã‚’è¨­å®šã—ã¾ã™ã€‚\n\n# 3. SARIMAãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰\n# order=(p, d, q), seasonal_order=(P, D, Q, s)\n# å‘¨æœŸ s=12 (æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿ã®ãŸã‚)\nsarima_model = SARIMAX(\n    df['Cost (100 million)'],\n    order=(1, 1, 1),\n    seasonal_order=(1, 1, 1, 12),\n    enforce_stationarity=False,\n    enforce_invertibility=False\n)\n\n# ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’\nsarima_result = sarima_model.fit()\n\nprint(sarima_result.summary())\n\n                                     SARIMAX Results                                      \n==========================================================================================\nDep. Variable:                 Cost (100 million)   No. Observations:                  120\nModel:             SARIMAX(1, 1, 1)x(1, 1, 1, 12)   Log Likelihood                -244.124\nDate:                               æ—¥, 14 12 2025   AIC                            498.249\nTime:                                    20:12:37   BIC                            510.912\nSample:                                01-01-2015   HQIC                           503.362\n                                     - 12-01-2024                                         \nCovariance Type:                              opg                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nar.L1          0.0269      0.121      0.223      0.824      -0.210       0.263\nma.L1         -1.0000    238.268     -0.004      0.997    -467.996     465.996\nar.S.L12      -0.2240      0.144     -1.554      0.120      -0.507       0.058\nma.S.L12      -0.5145      0.166     -3.101      0.002      -0.840      -0.189\nsigma2        10.2597   2444.753      0.004      0.997   -4781.367    4801.887\n===================================================================================\nLjung-Box (L1) (Q):                   0.01   Jarque-Bera (JB):                 0.43\nProb(Q):                              0.91   Prob(JB):                         0.81\nHeteroskedasticity (H):               0.95   Skew:                             0.08\nProb(H) (two-sided):                  0.88   Kurtosis:                         3.29\n===================================================================================\n\nWarnings:\n[1] Covariance matrix calculated using the outer product of gradients (complex-step)."
  },
  {
    "objectID": "demo/understanding_mercury/mine/sarima_demo.html#å‘ã“ã†5å¹´é–“ã®äºˆæ¸¬ã¨å¯è¦–åŒ–",
    "href": "demo/understanding_mercury/mine/sarima_demo.html#å‘ã“ã†5å¹´é–“ã®äºˆæ¸¬ã¨å¯è¦–åŒ–",
    "title": "SARIMAã‚’ä½¿ã£ãŸåŒ»ç™‚è²»äºˆæ¸¬ã®ãƒ‡ãƒ¢",
    "section": "å‘ã“ã†5å¹´é–“ã®äºˆæ¸¬ã¨å¯è¦–åŒ–",
    "text": "å‘ã“ã†5å¹´é–“ã®äºˆæ¸¬ã¨å¯è¦–åŒ–\n\n# 4. å‘ã“ã†5å¹´é–“ (60ãƒ¶æœˆ) ã®äºˆæ¸¬\nforecast_steps = 60\npred_uc = sarima_result.get_forecast(steps=forecast_steps)\n\n# äºˆæ¸¬å€¤ï¼ˆæœŸå¾…å€¤ï¼‰\npred_mean = pred_uc.predicted_mean\n\n# 95%ä¿¡é ¼åŒºé–“\npred_ci = pred_uc.conf_int()\n\n# --- å¯è¦–åŒ– ---\nfig_forecast = go.Figure()\n\n# 1. å®Ÿç¸¾å€¤ã®ãƒ—ãƒ­ãƒƒãƒˆ\nfig_forecast.add_trace(go.Scatter(\n    x=df.index,\n    y=df['Cost (100 million)'],\n    mode='lines',\n    name='å®Ÿç¸¾å€¤',\n    line=dict(color='blue')\n))\n\n# 2. äºˆæ¸¬å€¤ã®ãƒ—ãƒ­ãƒƒãƒˆ\nfig_forecast.add_trace(go.Scatter(\n    x=pred_mean.index,\n    y=pred_mean,\n    mode='lines',\n    name='äºˆæ¸¬å€¤ (ä»Šå¾Œ5å¹´)',\n    line=dict(color='red', dash='dash')\n))\n\n# 3. ä¿¡é ¼åŒºé–“ã®ãƒ—ãƒ­ãƒƒãƒˆ (ä¸Šé™ã¨ä¸‹é™ã®é–“ã‚’å¡—ã‚Šã¤ã¶ã™)\nfig_forecast.add_trace(go.Scatter(\n    x=pred_ci.index,\n    y=pred_ci.iloc[:, 0], # ä¸‹é™\n    mode='lines',\n    line=dict(width=0),\n    showlegend=False,\n    name='Lower Bound'\n))\n\nfig_forecast.add_trace(go.Scatter(\n    x=pred_ci.index,\n    y=pred_ci.iloc[:, 1], # ä¸Šé™\n    mode='lines',\n    line=dict(width=0),\n    fill='tonexty', # ã²ã¨ã¤å‰ã®ãƒˆãƒ¬ãƒ¼ã‚¹ï¼ˆä¸‹é™ï¼‰ã¨ã®é–“ã‚’åŸ‹ã‚ã‚‹\n    fillcolor='rgba(255, 0, 0, 0.2)', # èµ¤è‰²ã®åŠé€æ˜\n    name='95%ä¿¡é ¼åŒºé–“'\n))\n\nfig_forecast.update_layout(\n    title='SARIMAãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹åŒ»ç™‚è²»äºˆæ¸¬ï¼ˆå‘ã“ã†5å¹´ï¼‰',\n    xaxis_title='å¹´æœˆ',\n    yaxis_title='åŒ»ç™‚è²»',\n    template='plotly_white',\n    hovermode=\"x unified\"\n)\n\nfig_forecast.show(renderer=\"notebook\")"
  },
  {
    "objectID": "demo/understanding_mercury/mine/sarima_demo.html#åŒ»ç™‚è²»ä¸Šæ˜‡é‡‘é¡ã®ç®—å‡º",
    "href": "demo/understanding_mercury/mine/sarima_demo.html#åŒ»ç™‚è²»ä¸Šæ˜‡é‡‘é¡ã®ç®—å‡º",
    "title": "SARIMAã‚’ä½¿ã£ãŸåŒ»ç™‚è²»äºˆæ¸¬ã®ãƒ‡ãƒ¢",
    "section": "åŒ»ç™‚è²»ä¸Šæ˜‡é‡‘é¡ã®ç®—å‡º",
    "text": "åŒ»ç™‚è²»ä¸Šæ˜‡é‡‘é¡ã®ç®—å‡º\n\n# 5. ä¸Šæ˜‡é‡‘é¡ã®ç®—å‡º\n\n# ç›´è¿‘1å¹´é–“ã®å®Ÿç¸¾åˆè¨ˆ\nlast_year_actual = df['Cost (100 million)'].iloc[-12:].sum()\n\n# 5å¹´å¾Œï¼ˆäºˆæ¸¬æœŸé–“ã®æœ€å¾Œã®1å¹´é–“ï¼‰ã®äºˆæ¸¬åˆè¨ˆ\nlast_year_forecast = pred_mean.iloc[-12:].sum()\n\n# ä¸Šæ˜‡é¡ã¨ä¸Šæ˜‡ç‡\nincrease_amount = last_year_forecast - last_year_actual\nincrease_rate = (increase_amount / last_year_actual) * 100\n\nprint(f\"--- åŒ»ç™‚è²»ä¸Šæ˜‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ---\")\nprint(f\"ç›´è¿‘1å¹´é–“ã®åŒ»ç™‚è²»åˆè¨ˆ: {last_year_actual:,.2f}\")\nprint(f\"5å¹´å¾Œã®å¹´é–“åŒ»ç™‚è²»åˆè¨ˆ: {last_year_forecast:,.2f}\")\nprint(f\"--------------------------------\")\nprint(f\"å¹´é–“å¢—åŠ é¡: +{increase_amount:,.2f}\")\nprint(f\"ä¸Šæ˜‡ç‡: {increase_rate:.2f}%\")\n\n--- åŒ»ç™‚è²»ä¸Šæ˜‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ---\nç›´è¿‘1å¹´é–“ã®åŒ»ç™‚è²»åˆè¨ˆ: 1,777.19\n5å¹´å¾Œã®å¹´é–“åŒ»ç™‚è²»åˆè¨ˆ: 2,088.13\n--------------------------------\nå¹´é–“å¢—åŠ é¡: +310.94\nä¸Šæ˜‡ç‡: 17.50%"
  },
  {
    "objectID": "demo/understanding_mercury/sample/demo-slides.html",
    "href": "demo/understanding_mercury/sample/demo-slides.html",
    "title": "Interactive presentation ğŸ“",
    "section": "",
    "text": "import mercury as mr\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\napp = mr.App(title=\"Slides demo ğŸ“\", description=\"Wouldn't it be amazing to recompute slides during the show?\")"
  },
  {
    "objectID": "demo/understanding_mercury/sample/demo-slides.html#recompute-slides",
    "href": "demo/understanding_mercury/sample/demo-slides.html#recompute-slides",
    "title": "Interactive presentation ğŸ“",
    "section": "Recompute slides ğŸ–¥ï¸",
    "text": "Recompute slides ğŸ–¥ï¸\n\nYou can create interactive presentation with Mercury\nUsers can recompute slides by changing widgets\nYou can enter full screen by pressing F and exit with Esc\nPlease check next slides â¡ï¸\n\n\nname = mr.Text(label=\"What is your name?\", value=\"Piotr\")\n\n\nmr.Markdown(f\"\"\"## Hello {name.value}!\n\n{name.value}, this slide is recomputed after name change in the left side bar.\n\nPlease change the name value in the left side bar and press **Enter**.\n\nPlease check next slide â¡ï¸\n\n\"\"\")\n\n\nsamples = mr.Slider(label=\"How many samples\", value=75, min=50, max=100)\ncolor = mr.Select(label=\"Mark color\", value=\"blue\", choices=[\"blue\", \"green\", \"red\"])\n\n\nmr.Markdown(\"\"\"## Scatter plot ğŸ²\nPlease change number of samples and mark color in the left side bar. The plot will be updated during the slide show.\"\"\")\n_ = plt.plot(np.random.rand(samples.value), np.random.rand(samples.value), \"*\", color=color.value)"
  },
  {
    "objectID": "demo/understanding_mercury/sample/demo-slides.html#thank-you",
    "href": "demo/understanding_mercury/sample/demo-slides.html#thank-you",
    "title": "Interactive presentation ğŸ“",
    "section": "Thank you!",
    "text": "Thank you!\nPlease check our documentation at RunMercury.com for more information ğŸ“š"
  },
  {
    "objectID": "demo/understanding_mercury/sample/welcome.html",
    "href": "demo/understanding_mercury/sample/welcome.html",
    "title": "Welcome in Mercury ğŸ‘‹",
    "section": "",
    "text": "Mercury framework allows you easily turn Jupyter Notebooks into shareble web applications.\nYou can create beautiful and interactive web applications, reports, dashboards and presentations.\nMercury features: - add widgets with simple Python API, - simple cell execution model - widgets trigger cell execution below the widget definition, - hide or show notebook code, - share multiple notebooks, - executed notebook can be exported to HTML or PDF, - embed notebook apps on any website, - easily deploy (free & public Mercury cloud coming soon!) - easily add authentication to notebooks (coming soon!) - schedule automatic execution (coming soon!)\nPlease check our documentation at RunMercury.com for more information ğŸ“š\nThis text can be edited by changing welcome.md file. Demo notebooks can be edited in Jupyter.\nAll files created for demo are in the current directory."
  },
  {
    "objectID": "exe_data_analysis/steam-analysis/steam_data_extraction.html",
    "href": "exe_data_analysis/steam-analysis/steam_data_extraction.html",
    "title": "Tako Data Science Lab",
    "section": "",
    "text": "import os\nimport requests\nimport pandas as pd\n\n\n# api_key = os.environ.get(\"API_KEY\")\napi_key = \"A66BE6CD5BD8E918DE6C378BC9C8B5BC\"\n\nprint(api_key)\n\nA66BE6CD5BD8E918DE6C378BC9C8B5BC\n\n\n\ndef GetOwnedGames(api_key, uid):\n    url = \"http://api.steampowered.com/IPlayerService/GetOwnedGames/v1/?key={}&steamid={}&format=json\".format(\n        api_key, uid\n    )\n    r = requests.get(url)\n    data = json.loads(r.text)\n    return data[\"response\"]"
  }
]